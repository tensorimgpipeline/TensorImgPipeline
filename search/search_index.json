{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TensorImgPipeline","text":"<p>This is a repository for creating and running Tensor Image Pipelines, short tipis.</p>"},{"location":"#overview","title":"Overview","text":"<p>The TensorImgPipeline is a python package, which allows the developer to create new Deep Learning approaches in as a generalized Pipeline.</p> <p>The most approaches to new experiments are script or notebook based. While this approach helps to create fast results and showcase the Experiment, it is difficult to create a robust and repeatable structure.</p> <p>The script approach often leads to not maintainable code structure. Often multiple things are done in one place, which logical are only weakly connected. As example creating visualization, providing the visualization to the experiment server and training are often applied in the same script. Combined with configuration of those elements in the same script leads to a chaotic structure.</p> <p>We might need the structure, because they were a direct execution of our thoughts, which are also just came up while creating the first prototype of the experiment. But melting this chaos into a more structured and organized environment, often seems a huge effort. An effort where we might think it isn't worth it.</p> <p>At exactly this point TensorImgPipeline wants to shine. The Project provides the base structure to build structured, repeatable Experiments.</p> <p>To start the new experiment journey the developer/scientist/engineer just needs to categorize parts of the Experiments as Permanence or Process. After that, the Getting Started provide the information needed to build the structured Pipeline.</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>If you want to study how to execute already implemented pipelines, please refer Usage</p> <p>This document will teach how to create a new Pipeline, with all necessary parts.</p> <p>The document is written under the Assumption a developer has already created strong ideas, that should flow into a pipeline. This could be done on paper, script or notebook, but the final product should already kind of manifested. Better in text, but in mind is also no issue.</p> <p>As described in the Overview, the first step is to decide if a part of the pipeline is a <code>Permanence</code> or a <code>PipelineProcess</code>.</p>"},{"location":"getting_started/#internal-logic","title":"Internal logic","text":"<p>In detail the following image provides some information how the Pipeline is structured. If you do not want to read the internal logic jump straight to Create Config</p> <p></p> <p>UML Diagram sketch of <code>TensorImgPipeline</code></p> <p>In the diagram are the three main components of the TensorImgPipeline depicted. The <code>PipelineController</code> class is central part of the pipeline, storing and providing all the necessary components of the pipeline. The <code>Permanence</code> abstract class is used to create new implementations for objects which hold permanent information about the pipeline. As example a <code>Dataset</code> is a kind of information, which a process needs to access, but could be created without the flow of the pipeline. Compared to a script a <code>Dataset</code> is mostly an instance which is in the global scope. The <code>PipelineProcess</code> abstract class is the opposite to a <code>Permanence</code>. As example a <code>Visualization</code> creates a figure, which displays given batch of images as subplots with certain config. Of course, we could extract further parts of the <code>Visualization</code> as new <code>Permanence</code> implementations, as example the parameters of the figure.</p> <p>The <code>PipelineController</code> is instantiated with a dictionary of zero <code>Permanence</code> or more. This step is displayed as the aggregation<sup>1</sup>. Afterwards one <code>PipelineProcesse</code> or more are added to the <code>PipelineController</code>. This step is displayed as the composition<sup>1</sup>. The run method of the <code>PipelineController</code> class iterates over each <code>PipelineProcess</code> and calls it <code>execute</code> method, which uses (displayed as association<sup>1</sup>) the controller itself to access the <code>Permanence</code> if needed.</p> <p>Since doing this by hand is cumbersome and error-prone, a <code>PipelineBuilder</code> class is provided, which executes this behavior.</p>"},{"location":"getting_started/#create-config","title":"Create Config","text":"<p>After the decision which Parts fall into either the <code>Permanence</code> or the <code>PipelineProcess</code> category, the creation of the config files begins.</p> <p>It is not necessary to complete the configs at this point. The goal is to create a structure to begin with and complete later.</p> <p>Following steps are necessary to create the config structure:</p> <ol> <li>Create new folder under configs with the name of the Pipeline.</li> <li>Create <code>execute_pipeline.toml</code> file inside this folder.</li> <li>Create <code>initial_pipeline.toml</code> file inside this folder.</li> </ol>"},{"location":"getting_started/#the-initial_pipelinetoml","title":"The <code>initial_pipeline.toml</code>","text":"<p>Since not all components of a Pipeline should be part of the repository, it is necessary to provide such information.</p> <p>Following components of a Pipeline needed to be defined inside this config:</p> <ul> <li>Dependencies</li> <li>Dataset locations</li> <li>Model locations</li> </ul> <p>An Example config could look like the following:</p> <pre><code>[dependencies.submodules.sam]\nname = \"segment_anything\"\nurl = \"https://github.com/facebookresearch/segment-anything.git\"\ncommit = \"dca509fe\"\n\n[data.datasets.pascal]\nlocation = \"/mnt/data1/datasets/image/voc/VOCdevkit/VOC2012/\"\nformat = \"pascalvoc\"\n\n[data.models.sam]\nlocation = \"/mnt/data1/models/sam/sam_vit_h_4b8939.pth\"\nformat = \"pth\"\n</code></pre> <p>The dependency is in this case a git submodule, but could be also a pip package. The dependencies will be installed via <code>uv pip install</code>, so it will not interfere with <code>pyproject.toml</code>.</p> <p>A dataset and a model are always provided with a key (<code>pascal</code> or <code>sam</code> in this case), a location and a format. The key will be used to create the symlink below <code>data/dataset</code> or <code>data/models</code> based on location. The format helps to reduce Boilerplate for dataset creation.</p>"},{"location":"getting_started/#the-execute_pipelinetoml","title":"The <code>execute_pipeline.toml</code>","text":"<p>This config file is used to provide the different <code>Permanence</code> and <code>PipelineProcess</code> object configurations.</p> <p>An example config could look like the following:</p> <pre><code>[permanences.data]\ntype = \"Datasets\"\nparams = { root = \"localhost\", format = \"pascalvoc\" }\n\n[processes.viz]\ntype = \"Visualization\"\n</code></pre> <p>Here are one <code>Permanence</code> and one <code>PipelineProcess</code> object provided. The <code>params</code> field is always Optional. The <code>type</code> field provides the classes of the Pipeline, which we need to create inside our Pipeline Library. The <code>params</code> need to match accordingly to the <code>__init__</code> method of the Implementation.</p> <p>Additional configuration for provided <code>Permanence</code> or <code>PipelineProcess</code> classes could here be provided. As example from the core package the <code>Visualization</code> process is defined in the config. The <code>Builder</code> will first register the <code>Visualization</code> class from core package. It is also possible to override the <code>Visualization</code> class inside the pipeline library.</p>"},{"location":"getting_started/#create-pipeline-library","title":"Create Pipeline Library","text":"<p>With the initiation of the config files we can begin creating the actual pipeline library. It is necessary to create for every entry in the config its implementation, but we have the freedom to provide additional pipeline internal structure. The structure of a new pipeline subpackage looks the following:</p> <pre><code>\ud83d\udce6tipi\n \u2517 \ud83d\udce6pipelines\n    \u2517 \ud83d\udce6node_modules\n       \u2523 \ud83d\udcdc__init__.py\n       \u2523 \ud83d\udcdcpermanences.py\n       \u2517 \ud83d\udcdcprocesses.py\n</code></pre> <p>Following the structure the implementations should be provided dependent on the config either inside the <code>permanences.py</code> or <code>processes.py</code> module. This is just a recommendation to follow the pattern of the package, but a developer can decide against the pattern. The only necessary part is the announcement of the <code>Permanence</code> and the <code>PipelineProcess</code> inside the subpackage <code>__init__.py</code> module.</p> <p>For the previous example the <code>__init__.py</code> module looks the following:</p> <pre><code>from permaneces import Datasets\nfrom processes import DummyProcess\n\npermanences_to_register = {\"Datasets\": Datasets}\nprocesses_to_register = {\"Visualization\": Visualization}\n</code></pre>"},{"location":"getting_started/#execute-or-testing","title":"Execute or testing","text":"<p>From that point there are initial two possible ways to proceed.</p> <ol> <li>Execute the Pipeline directly</li> </ol> <p>This could be a good start point to get familiar how the pipeline works and looks as the final product. It is good practice to follow this approach if the developer works first time with this project. Nevertheless, the second way is an absolute recommendation, to create the final pipeline.</p> <ol> <li>Creating test cases</li> </ol> <p>The creation of test cases is a recommended approach, since at the end multiple small components of the pipeline are provided. Instead of running all the time the complete pipeline, checking each bit with artificial and abstract test cases could provide spare time. Not only this, after iterating through changes in the pipeline library, we are able to verify the correctness of the step in the Pipeline. In a certain situation it might be necessary to extend the test case to fulfil new challenges, which were not thought about at the beginning of the Pipeline development.</p>"},{"location":"getting_started/#documentation","title":"Documentation","text":"<p>As the last step or in parallel while developing a new pipeline, documenting the pipeline is a key feature of this package.</p> <ul> <li>Create a new markdown file with the name of the pipeline under <code>docs/pipelines</code>.</li> <li>Fill the markdown with the description, goal and results of the pipeline.</li> <li>As example the <code>Visualization</code> could directly output images for documentation to the <code>docs/assets</code> location.</li> <li>Add the markdown file to navigation in <code>mkdocs.yml</code>:</li> </ul> <pre><code>@@ -12,7 +12,8 @@ nav:\n   - Installation: installation.md\n   - Usage: usage.md\n   - Getting Started: getting_started.md\n   - Pipelines:\n+      - new_pipeline: pipelines/new_pipeline.md\n   - Modules:\n       - builder.py: modules/builder.md\n       - controller.py: modules/controller.md\n</code></pre> <p>Additional also extending the module section is possible.</p> <ol> <li> <p>A short explanation between an aggregation vs. composition vs. association.\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"ideas/","title":"Ideas","text":"<p>This Chapter describes Ideas to enhance the project. It can be interpreted as lists of TODOS.</p>"},{"location":"ideas/#nested-process-bars","title":"Nested Process Bars","text":"<p>Since a pipeline does have various steps we want an informative way to show the status of the current running pipeline.</p> <p>Here are two approaches for nested progress bars:</p> TQDMRICH <p>source</p> <pre><code>from tqdm import tqdm\n# from tqdm.auto import tqdm  # notebook compatible\nimport time\nfor i1 in tqdm(range(5)):\n    for i2 in tqdm(range(300), leave=False):\n        # do something, e.g. sleep\n        time.sleep(0.01)\n</code></pre> <p>source</p> <pre><code>import time\n\nfrom rich.progress import Progress\n\nwith Progress() as progress:\n\n    task1 = progress.add_task(\"[red]Downloading...\", total=1000)\n    task2 = progress.add_task(\"[green]Processing...\", total=1000)\n    task3 = progress.add_task(\"[cyan]Cooking...\", total=1000)\n\n    while not progress.finished:\n        progress.update(task1, advance=0.5)\n        progress.update(task2, advance=0.3)\n        progress.update(task3, advance=0.9)\n        time.sleep(0.02)\n</code></pre>"},{"location":"ideas/#ansolved-questions","title":"Ansolved Questions:","text":"<ul> <li>How to handle monitoring of internal loops?</li> </ul>"},{"location":"ideas/#tensorboard-process","title":"Tensorboard Process","text":"<p>A core Tensorboard process which based on config creates different visualizations.</p>"},{"location":"ideas/#wandb-process","title":"Wandb Process","text":"<p>A core Wandb process which based on config creates different visualizations and perform hyperparam trainings.</p>"},{"location":"ideas/#prerun-validation","title":"PreRun Validation","text":"<p>Since we create mostly everything dynamic from the config and only checking that the general structure of the config is correct, also validating the actual run before executing, would be beneficial. Since most Processes will access Permanences of the PipelineController, we could before the final execution check that every call of controller.used_permanence of every process doesn't result in a <code>NameError</code> (if <code>Permanence</code> is not defined), <code>AttributeError</code> (if <code>Permanence</code> does not have given Attribute) or <code>TypeError</code> (if <code>Permanece</code> method got not the correct Attributes).</p> <p>The Pipeline can still crash caused by internal other errors, but we ensure, that the Process will not fail caused by issue in the config.</p>"},{"location":"ideas/#init-script-cli-command-for-new-pipelines","title":"Init Script / cli command for new Pipelines","text":"<p>A init script or cli command could speed up start times.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"usage/","title":"Usage","text":""},{"location":"generated/architecture_diagram/","title":"TensorImgPipeline - Proposed Architecture","text":"<p>Philosophy: Progressive Enhancement - Start Simple, Scale When Needed</p> <p>This architecture supports researchers from initial script to production pipeline with minimal friction at each step.</p>"},{"location":"generated/architecture_diagram/#overview-architecture-diagram","title":"Overview Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                  CLI LAYER                                 \u2502\n\u2502                               (cli.py)                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  \u2022 Parse command line arguments with Typer                          \u2502   \u2502\n\u2502  \u2502  \u2022 Display formatted errors with Rich                               \u2502   \u2502\n\u2502  \u2502  \u2022 Delegate to PipelineRunner                                       \u2502   \u2502\n\u2502  \u2502                                                                     \u2502   \u2502\n\u2502  \u2502  @app.command()                                                     \u2502   \u2502\n\u2502  \u2502  def build_pipeline(pipeline_name: str):                            \u2502   \u2502\n\u2502  \u2502      runner = PipelineRunner(pipeline_name)                         \u2502   \u2502\n\u2502  \u2502      runner.run()                                                   \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                        \u2502\n                                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          APPLICATION LAYER                              \u2502\n\u2502                            (runner.py)                                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502  class PipelineRunner:                                              \u2502 \u2502\n\u2502 \u2502      \u2022 High-level orchestration                                     \u2502 \u2502\n\u2502 \u2502      \u2022 Coordinates Builder \u2192 Controller \u2192 Executor                  \u2502 \u2502\n\u2502 \u2502      \u2022 Handles WandB sweep integration                              \u2502 \u2502\n\u2502 \u2502      \u2022 Provides programmatic API entry point                        \u2502 \u2502\n\u2502 \u2502                                                                     \u2502 \u2502\n\u2502 \u2502      def build() -&gt; (controller, error)                             \u2502 \u2502\n\u2502 \u2502      def run() -&gt; None                                              \u2502 \u2502\n\u2502 \u2502      def _run_once(controller) -&gt; None                              \u2502 \u2502\n\u2502 \u2502      def _run_with_sweep(controller, wandb) -&gt; None                 \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                        \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u25bc                                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         BUILDER LAYER                  \u2502   \u2502      CONTROLLER LAYER          \u2502\n\u2502         (builder.py)                   \u2502   \u2502      (controller.py)           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  class PipelineBuilder:         \u2502   \u2502   \u2502  \u2502  class PipelineController \u2502 \u2502\n\u2502  \u2502    \u2022 Load &amp; validate config     \u2502   \u2502   \u2502  \u2502    \u2022 Manage permanence    \u2502 \u2502\n\u2502  \u2502    \u2022 Register classes           \u2502   \u2502   \u2502  \u2502      lifecycle            \u2502 \u2502\n\u2502  \u2502    \u2022 Build permanences          \u2502   \u2502   \u2502  \u2502    \u2022 Provide permanence   \u2502 \u2502\n\u2502  \u2502    \u2022 Build process specs        \u2502   \u2502   \u2502  \u2502      access               \u2502 \u2502\n\u2502  \u2502                                 \u2502   \u2502   \u2502  \u2502    \u2022 Instantiate          \u2502 \u2502\n\u2502  \u2502    def build() -&gt;               \u2502   \u2502   \u2502  \u2502      processes            \u2502 \u2502\n\u2502  \u2502      (permanences,              \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u25b6\u2502    \u2022 Coordinate cleanup   \u2502 \u2502\n\u2502  \u2502       process_specs,            \u2502   \u2502   \u2502  \u2502                           \u2502 \u2502\n\u2502  \u2502       error)                    \u2502   \u2502   \u2502  \u2502    Methods:               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502  \u2502    \u2022 initialize_          \u2502 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502      permanences()        \u2502 \u2502\n                                             \u2502  \u2502    \u2022 validate_            \u2502 \u2502\n                                             \u2502  \u2502      permanences()        \u2502 \u2502\n                                             \u2502  \u2502    \u2022 checkpoint_          \u2502 \u2502\n                                             \u2502  \u2502      permanences()        \u2502 \u2502\n                                             \u2502  \u2502    \u2022 get_permanence()     \u2502 \u2502\n                                             \u2502  \u2502    \u2022 iterate_processes()  \u2502 \u2502\n                                             \u2502  \u2502    \u2022 cleanup()            \u2502 \u2502\n                                             \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n                                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                            \u2502\n                                                            \u25bc\n                                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                               \u2502      EXECUTOR LAYER           \u2502\n                                               \u2502      (executor.py)            \u2502\n                                               \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n                                               \u2502  \u2502  class PipelineExecutor\u2502   \u2502\n                                               \u2502  \u2502    \u2022 Execute processes \u2502   \u2502\n                                               \u2502  \u2502    \u2022 Apply progress    \u2502   \u2502\n                                               \u2502  \u2502      decoration        \u2502   \u2502\n                                               \u2502  \u2502    \u2022 Handle nested     \u2502   \u2502\n                                               \u2502  \u2502      progress bars     \u2502   \u2502\n                                               \u2502  \u2502    \u2022 Integrate WandB   \u2502   \u2502\n                                               \u2502  \u2502    \u2022 Error handling    \u2502   \u2502\n                                               \u2502  \u2502                        \u2502   \u2502\n                                               \u2502  \u2502    Methods:            \u2502   \u2502\n                                               \u2502  \u2502    \u2022 run()             \u2502   \u2502\n                                               \u2502  \u2502    \u2022 _run_processes()  \u2502   \u2502\n                                               \u2502  \u2502    \u2022 _run_cleanup()    \u2502   \u2502\n                                               \u2502  \u2502    \u2022 _handle_error()   \u2502   \u2502\n                                               \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                            \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u25bc                                                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         PERMANENCES                     \u2502              \u2502         PROCESSES              \u2502\n\u2502         (abstractions.py)               \u2502              \u2502         (abstractions.py)      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502              \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  class Permanence(ABC):          \u2502   \u2502              \u2502  \u2502  class PipelineProcess:  \u2502  \u2502\n\u2502  \u2502    \u2022 cleanup()                   \u2502   \u2502              \u2502  \u2502    \u2022 execute()           \u2502  \u2502\n\u2502  \u2502    \u2022 initialize() [optional]     \u2502   \u2502              \u2502  \u2502    \u2022 skip()              \u2502  \u2502\n\u2502  \u2502    \u2022 validate() [optional]       \u2502   \u2502              \u2502  \u2502    \u2022 Access controller   \u2502  \u2502\n\u2502  \u2502    \u2022 checkpoint() [optional]     \u2502   \u2502              \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u2502    \u2022 get_state() [optional]      \u2502   \u2502              \u2502                                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502              \u2502  Implementations:              \u2502\n\u2502                                         \u2502              \u2502  \u2022 ResultProcess               \u2502\n\u2502  Implementations:                       \u2502              \u2502  \u2022 TrainingProcess             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502              \u2502  \u2022 ValidationProcess           \u2502\n\u2502  \u2502  Device                          \u2502   \u2502              \u2502  \u2022 TestProcess                 \u2502\n\u2502  \u2502    \u2022 Manages CUDA device         \u2502   \u2502              \u2502  \u2022 DataLoadProcess             \u2502\n\u2502  \u2502    \u2022 Selects best GPU            \u2502   \u2502              \u2502  \u2022 ...custom processes         \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502  \u2502  ProgressManager                 \u2502   \u2502\n\u2502  \u2502    \u2022 Rich progress bars          \u2502   \u2502\n\u2502  \u2502    \u2022 Nested progress tracking    \u2502   \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502  \u2502  WandBManager                    \u2502   \u2502\n\u2502  \u2502    \u2022 Experiment logging          \u2502   \u2502\n\u2502  \u2502    \u2022 Sweep management            \u2502   \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502  \u2502  Network                         \u2502   \u2502\n\u2502  \u2502    \u2022 Model instance              \u2502   \u2502\n\u2502  \u2502    \u2022 Model state                 \u2502   \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502  \u2502  Data                            \u2502   \u2502\n\u2502  \u2502    \u2022 Datasets                    \u2502   \u2502\n\u2502  \u2502    \u2022 Data loaders                \u2502   \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502  \u2502  Hyperparameters                 \u2502   \u2502\n\u2502  \u2502    \u2022 Configuration               \u2502   \u2502\n\u2502  \u2502    \u2022 Sweep config                \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#permanence-lifecycle-diagram","title":"Permanence Lifecycle Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        PERMANENCE LIFECYCLE                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nPhase 1: CONSTRUCTION\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Builder instantiates permanence with config params         \u2502\n\u2502  permanence = Device()                                      \u2502\n\u2502  permanence = ProgressManager(console=console)              \u2502\n\u2502  permanence = WandBManager(project=\"...\", entity=\"...\")     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u25bc\nPhase 2: INITIALIZATION (Controller)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  controller.initialize_permanences()                        \u2502\n\u2502    \u2192 permanence.initialize()                                \u2502\n\u2502       \u2022 Validate dependencies exist                         \u2502\n\u2502       \u2022 Allocate resources (memory, GPU)                    \u2502\n\u2502       \u2022 Setup connections (WandB, databases)                \u2502\n\u2502       \u2022 Verify configuration validity                       \u2502\n\u2502                                                             \u2502\n\u2502  Example: Device.initialize()                               \u2502\n\u2502    - Checks CUDA availability                               \u2502\n\u2502    - Validates VRAM thresholds                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u25bc\nPhase 3: VALIDATION (Executor - Optional)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  controller.validate_permanences()                          \u2502\n\u2502    \u2192 permanence.validate()                                  \u2502\n\u2502       \u2022 Health checks                                       \u2502\n\u2502       \u2022 State verification                                  \u2502\n\u2502       \u2022 Consistency checks                                  \u2502\n\u2502                                                             \u2502\n\u2502  Example: Device.validate()                                 \u2502\n\u2502    - Checks VRAM usage &lt; 95%                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u25bc\nPhase 4: EXECUTION (Processes access permanences)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Process execution:                                         \u2502\n\u2502    device = controller.get_permanence(\"device\")             \u2502\n\u2502    progress = controller.get_permanence(\"progress_manager\") \u2502\n\u2502    wandb = controller.get_permanence(\"wandb_logger\")        \u2502\n\u2502                                                             \u2502\n\u2502  Processes use permanences throughout execution:            \u2502\n\u2502    \u2022 Access device for GPU operations                       \u2502\n\u2502    \u2022 Update progress bars                                   \u2502\n\u2502    \u2022 Log metrics to WandB                                   \u2502\n\u2502    \u2022 Load data from datasets                                \u2502\n\u2502                                                             \u2502\n\u2502  Nested progress bars created by processes:                 \u2502\n\u2502    @progress_manager.progress_task(\"train\")                 \u2502\n\u2502    def train_epoch(task_id, total, progress):               \u2502\n\u2502        for batch in dataloader:                             \u2502\n\u2502            progress.advance(task_id)                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u25bc\nPhase 5: CHECKPOINTING (Executor - Optional)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  controller.checkpoint_permanences()                        \u2502\n\u2502    \u2192 permanence.checkpoint()                                \u2502\n\u2502       \u2022 Save intermediate state                             \u2502\n\u2502       \u2022 Create backups                                      \u2502\n\u2502       \u2022 Log checkpoint metrics                              \u2502\n\u2502                                                             \u2502\n\u2502  Example: Network.checkpoint()                              \u2502\n\u2502    - Saves model weights                                    \u2502\n\u2502    - Saves optimizer state                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u25bc\nPhase 6: CLEANUP (Always executed)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  controller.cleanup()                                       \u2502\n\u2502    \u2192 permanence.cleanup()                                   \u2502\n\u2502       \u2022 Release memory (RAM/VRAM)                           \u2502\n\u2502       \u2022 Close file handles                                  \u2502\n\u2502       \u2022 Close network connections                           \u2502\n\u2502       \u2022 Finalize logging                                    \u2502\n\u2502       \u2022 Save final state                                    \u2502\n\u2502                                                             \u2502\n\u2502  Example: Device.cleanup()                                  \u2502\n\u2502    - Clears CUDA cache                                      \u2502\n\u2502  Example: WandBManager.cleanup()                            \u2502\n\u2502    - Finalizes WandB run                                    \u2502\n\u2502  Example: ProgressManager.cleanup()                         \u2502\n\u2502    - Closes progress bars                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#data-flow-diagram","title":"Data Flow Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            DATA FLOW                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n1. Configuration Loading\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 TOML Config    \u2502\n   \u2502 Files          \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 PipelineBuilder\u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 Class Registry   \u2502\n   \u2502                \u2502       \u2502 (Permanences +   \u2502\n   \u2502 \u2022 Load TOML    \u2502       \u2502  Processes)      \u2502\n   \u2502 \u2022 Validate     \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n   \u2502 \u2022 Parse        \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Permanence Instances           \u2502\n   \u2502 + Process Specifications       \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u25bc\n\n2. Pipeline Execution Flow\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 PipelineRunner                                          \u2502\n   \u2502   runner.run()                                          \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502               \u2502               \u2502\n       \u25bc               \u25bc               \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Builder \u2502   \u2502Controller\u2502  \u2502Executor \u2502\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n        \u2502             \u2502              \u2502\n        \u2502 build()     \u2502              \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502              \u2502\n        \u2502             \u2502              \u2502\n        \u2502         initialize_        \u2502\n        \u2502         permanences()      \u2502\n        \u2502             \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502\n        \u2502             \u2502              \u2502\n        \u2502             \u2502         validate_\n        \u2502             \u2502         permanences()\n        \u2502             \u2502              \u2502\n        \u2502             \u2502              \u2502\n        \u2502             \u2502         run()\u2502\n        \u2502             \u2502              \u251c\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502             \u2502              \u2502     \u2502\n        \u2502             \u2502              \u2502  Execute Processes\n        \u2502             \u2502              \u2502     \u2502\n        \u2502             \u2502              \u2502     \u25bc\n        \u2502             \u2502              \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502             \u2502              \u2502  \u2502 Process 1    \u2502\n        \u2502             \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2502 get_perm()   \u2502\n        \u2502             \u2502              \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502             \u2502              \u2502     \u2502\n        \u2502             \u2502              \u2502     \u25bc\n        \u2502             \u2502              \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502             \u2502              \u2502  \u2502 Process 2    \u2502\n        \u2502             \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2502 get_perm()   \u2502\n        \u2502             \u2502              \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502             \u2502              \u2502     \u2502\n        \u2502             \u2502              \u2502     \u25bc\n        \u2502             \u2502              \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502             \u2502              \u2502  \u2502 Process N    \u2502\n        \u2502             \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2502 get_perm()   \u2502\n        \u2502             \u2502              \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502             \u2502              \u2502      \u2502\n        \u2502             \u2502              \u2502  checkpoint_\n        \u2502             \u2502              \u2502  permanences()\n        \u2502             \u2502              \u25c0\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502             \u2502              \u2502\n        \u2502             \u2502         cleanup()\n        \u2502             \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n        \u2502             \u2502              \u2502\n        \u2502         cleanup()          \u2502\n        \u2502             \u2502              \u2502\n        \u25bc             \u25bc              \u25bc\n</code></pre>"},{"location":"generated/architecture_diagram/#process-access-pattern","title":"Process Access Pattern","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PROCESS PERMANENCE ACCESS                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  class TrainingProcess(PipelineProcess):                      \u2502\n  \u2502                                                               \u2502\n  \u2502      def __init__(self, controller, force, epochs):           \u2502\n  \u2502          super().__init__(controller, force)                  \u2502\n  \u2502                                                               \u2502\n  \u2502          # Access permanences through controller              \u2502\n  \u2502          self.device = controller.get_permanence(\"device\")    \u2502\n  \u2502          self.network = controller.get_permanence(\"network\")  \u2502\n  \u2502          self.progress = controller.get_permanence(           \u2502\n  \u2502              \"progress_manager\"                               \u2502\n  \u2502          )                                                    \u2502\n  \u2502          self.wandb = controller.get_permanence(              \u2502\n  \u2502              \"wandb_logger\"                                   \u2502\n  \u2502          )                                                    \u2502\n  \u2502          self.data = controller.get_permanence(\"data\")        \u2502\n  \u2502                                                               \u2502\n  \u2502      def execute(self) -&gt; Optional[Exception]:                \u2502\n  \u2502          # Use permanences in execution                       \u2502\n  \u2502          model = self.network.model_instance                  \u2502\n  \u2502          model.to(self.device.device)                         \u2502\n  \u2502                                                               \u2502\n  \u2502          # Create nested progress bar                         \u2502\n  \u2502          @self.progress.progress_task(\"train\")                \u2502\n  \u2502          def train_loop(task_id, total, progress):            \u2502\n  \u2502              for epoch in range(total):                       \u2502\n  \u2502                  loss = self._train_epoch(model)              \u2502\n  \u2502                  self.wandb.log_metrics({\"loss\": loss})       \u2502\n  \u2502                  progress.advance(task_id)                    \u2502\n  \u2502                                                               \u2502\n  \u2502          train_loop(self.epochs)                              \u2502\n  \u2502          return None                                          \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u2502 Access Pattern\n                                    \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  PipelineController                                           \u2502\n  \u2502                                                               \u2502\n  \u2502  _permanences = {                                             \u2502\n  \u2502      \"device\": &lt;Device instance&gt;,                             \u2502\n  \u2502      \"network\": &lt;Network instance&gt;,                           \u2502\n  \u2502      \"progress_manager\": &lt;ProgressManager instance&gt;,          \u2502\n  \u2502      \"wandb_logger\": &lt;WandBManager instance&gt;,                 \u2502\n  \u2502      \"data\": &lt;Data instance&gt;                                  \u2502\n  \u2502  }                                                            \u2502\n  \u2502                                                               \u2502\n  \u2502  def get_permanence(self, name: str) -&gt; Any:                  \u2502\n  \u2502      if name not in self._permanences:                        \u2502\n  \u2502          raise PermanenceKeyError(...)                        \u2502\n  \u2502      return self._permanences[name]                           \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#wandb-integration-flow","title":"WandB Integration Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         WandB INTEGRATION                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nStandard Run (No Sweep)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  PipelineRunner.run()                                   \u2502\n\u2502    \u2502                                                    \u2502\n\u2502    \u251c\u2500 Check for WandB sweep config                      \u2502\n\u2502    \u2502    wandb = controller.get_permanence(\"wandb\")      \u2502\n\u2502    \u2502    if not wandb.sweep_id:                          \u2502\n\u2502    \u2502                                                    \u2502\n\u2502    \u2514\u2500\u25b6 runner._run_once(controller)                    \u2502\n\u2502          \u2502                                              \u2502\n\u2502          \u2514\u2500\u25b6 PipelineExecutor.run()                    \u2502\n\u2502                \u2502                                        \u2502\n\u2502                \u251c\u2500 wandb.init_wandb()  # Init single run \u2502\n\u2502                \u2502                                        \u2502\n\u2502                \u251c\u2500 executor._run_processes()             \u2502\n\u2502                \u2502    \u2514\u2500\u25b6 Processes log to WandB         \u2502\n\u2502                \u2502                                        \u2502\n\u2502                \u2514\u2500 executor._run_cleanup()               \u2502\n\u2502                     \u2514\u2500\u25b6 wandb.cleanup() # Finalize run \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nSweep Run (Multiple Runs)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  PipelineRunner.run()                                  \u2502\n\u2502    \u2502                                                   \u2502\n\u2502    \u251c\u2500 Check for WandB sweep config                     \u2502\n\u2502    \u2502    wandb = controller.get_permanence(\"wandb\")     \u2502\n\u2502    \u2502    hyperparams = controller.get_permanence(       \u2502\n\u2502    \u2502        \"hyperparams\"                              \u2502\n\u2502    \u2502    )                                              \u2502\n\u2502    \u2502    if wandb.sweep_id:                             \u2502\n\u2502    \u2502                                                   \u2502\n\u2502    \u2514\u2500\u25b6 runner._run_with_sweep(controller, wandb)      \u2502\n\u2502          \u2502                                             \u2502\n\u2502          \u251c\u2500 wandb.create_sweep(                        \u2502\n\u2502          \u2502     hyperparams.sweep_configuration         \u2502\n\u2502          \u2502 )                                           \u2502\n\u2502          \u2502                                             \u2502\n\u2502          \u2514\u2500 wandb.create_sweep_agent(                  \u2502\n\u2502                function=lambda: runner._run_once()     \u2502\n\u2502            )                                           \u2502\n\u2502             \u2502                                          \u2502\n\u2502             \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Agent spawns N runs \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502             \u2502   \u2502                                    \u2502 \u2502\n\u2502             \u2514\u2500\u25b6\u2502  Run 1:                            \u2502 \u2502\n\u2502                 \u2502    wandb.init_wandb()              \u2502 \u2502\n\u2502                 \u2502    executor._run_processes()       \u2502 \u2502\n\u2502                 \u2502    wandb.cleanup()                 \u2502 \u2502\n\u2502                 \u2502                                    \u2502 \u2502\n\u2502                 \u2502  Run 2:                            \u2502 \u2502\n\u2502                 \u2502    wandb.init_wandb()              \u2502 \u2502\n\u2502                 \u2502    executor._run_processes()       \u2502 \u2502\n\u2502                 \u2502    wandb.cleanup()                 \u2502 \u2502\n\u2502                 \u2502                                    \u2502 \u2502\n\u2502                 \u2502  ...                               \u2502 \u2502\n\u2502                 \u2502                                    \u2502 \u2502\n\u2502                 \u2502  Run N:                            \u2502 \u2502\n\u2502                 \u2502    wandb.init_wandb()              \u2502 \u2502\n\u2502                 \u2502    executor._run_processes()       \u2502 \u2502\n\u2502                 \u2502    wandb.cleanup()                 \u2502 \u2502\n\u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#progress-bar-nesting-example","title":"Progress Bar Nesting Example","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    NESTED PROGRESS BARS                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nVisual Output:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Overall      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 (2/5) \u2022 00:15:30          \u2502 \u2190 Executor\n\u2502 Cleanup      \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 (0/6) \u2022 00:00:00          \u2502 \u2190 Executor\n\u2502 Epoch        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 (2/3) \u2022 Status: Train     \u2502 \u2190 Process\n\u2502 Train-Val    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 (100/100) \u2022 00:02:15      \u2502 \u2190 Process\n\u2502 Result       \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 (0/15) \u2022 00:00:00         \u2502 \u2190 Process\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nCode Flow:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 PipelineExecutor                                         \u2502\n\u2502                                                          \u2502\n\u2502   @progress_decorator(\"overall\")  # Top-level bar        \u2502\n\u2502   def _execute(task_id, total, progress):                \u2502\n\u2502       for idx, process in enumerate(processes):          \u2502\n\u2502           process.execute()  # Process creates nested    \u2502\n\u2502           progress.advance(task_id)                      \u2502\n\u2502                                                          \u2502\n\u2502   @progress_decorator(\"cleanup\")  # Top-level bar        \u2502\n\u2502   def _cleanup(task_id, total, progress):                \u2502\n\u2502       controller.cleanup()                               \u2502\n\u2502       progress.advance(task_id)                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 TrainingProcess                                          \u2502\n\u2502                                                          \u2502\n\u2502   def execute(self):                                     \u2502\n\u2502       @self.progress.progress_task(\"epoch\")              \u2502\n\u2502       def train_epochs(task_id, total, progress):        \u2502\n\u2502           for epoch in range(total):                     \u2502\n\u2502               @self.progress.progress_task(\"train-val\")  \u2502\n\u2502               def train_val(tid, tot, prog):             \u2502\n\u2502                   for batch in dataloader:               \u2502\n\u2502                       # Training logic                   \u2502\n\u2502                       prog.advance(tid)                  \u2502\n\u2502               train_val(num_batches)                     \u2502\n\u2502               progress.advance(task_id)                  \u2502\n\u2502                                                          \u2502\n\u2502       train_epochs(self.epochs)                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#testing-strategy","title":"Testing Strategy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TESTING LAYERS                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nUnit Tests:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 test_permanences.py                                \u2502\n\u2502   \u2022 Test each permanence in isolation              \u2502\n\u2502   \u2022 Mock dependencies                              \u2502\n\u2502   \u2022 Test lifecycle methods                         \u2502\n\u2502                                                    \u2502\n\u2502 test_builder.py                                    \u2502\n\u2502   \u2022 Test config loading                            \u2502\n\u2502   \u2022 Test class registration                        \u2502\n\u2502   \u2022 Test permanence/process building               \u2502\n\u2502                                                    \u2502\n\u2502 test_controller.py                                 \u2502\n\u2502   \u2022 Test permanence access                         \u2502\n\u2502   \u2022 Test process iteration                         \u2502\n\u2502   \u2022 Test lifecycle coordination                    \u2502\n\u2502                                                    \u2502\n\u2502 test_executor.py                                   \u2502\n\u2502   \u2022 Test process execution                         \u2502\n\u2502   \u2022 Test error handling                            \u2502\n\u2502   \u2022 Mock progress manager                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nIntegration Tests:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 test_pipeline_integration.py                       \u2502\n\u2502   \u2022 Test Builder \u2192 Controller \u2192 Executor flow      \u2502\n\u2502   \u2022 Use mock permanences and processes             \u2502\n\u2502   \u2022 Verify data flow                               \u2502\n\u2502                                                    \u2502\n\u2502 test_runner.py                                     \u2502\n\u2502   \u2022 Test PipelineRunner end-to-end                 \u2502\n\u2502   \u2022 Mock WandB integration                         \u2502\n\u2502   \u2022 Test programmatic API                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nProgrammatic Testing Example:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 # No CLI needed!                                   \u2502\n\u2502                                                    \u2502\n\u2502 def test_pipeline_execution():                     \u2502\n\u2502     # Create mock permanences                      \u2502\n\u2502     permanences = {                                \u2502\n\u2502         \"device\": MockDevice(),                    \u2502\n\u2502         \"network\": MockNetwork(),                  \u2502\n\u2502         \"progress_manager\": None,  # Optional      \u2502\n\u2502     }                                              \u2502\n\u2502                                                    \u2502\n\u2502     # Create mock process specs                    \u2502\n\u2502     process_specs = [                              \u2502\n\u2502         ProcessWithParams(                         \u2502\n\u2502             MockProcess,                           \u2502\n\u2502             {\"force\": False}                       \u2502\n\u2502         )                                          \u2502\n\u2502     ]                                              \u2502\n\u2502                                                    \u2502\n\u2502     # Create controller                            \u2502\n\u2502     controller = PipelineController(               \u2502\n\u2502         permanences,                               \u2502\n\u2502         process_specs                              \u2502\n\u2502     )                                              \u2502\n\u2502                                                    \u2502\n\u2502     # Execute                                      \u2502\n\u2502     executor = PipelineExecutor(controller)        \u2502\n\u2502     executor.run()                                 \u2502\n\u2502                                                    \u2502\n\u2502     # Verify results                               \u2502\n\u2502     assert MockProcess.executed                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#key-benefits-summary","title":"Key Benefits Summary","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            KEY BENEFITS                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u2713 Clear Separation of Concerns\n  \u251c\u2500 CLI: User interaction only\n  \u251c\u2500 Runner: Orchestration\n  \u251c\u2500 Builder: Component construction\n  \u251c\u2500 Controller: Lifecycle management\n  \u2514\u2500 Executor: Execution &amp; visualization\n\n\u2713 Testability\n  \u251c\u2500 Each layer independently testable\n  \u251c\u2500 Mock permanences and processes\n  \u2514\u2500 No CLI required for testing\n\n\u2713 Reusability\n  \u251c\u2500 Programmatic API via PipelineRunner\n  \u251c\u2500 Can embed in other applications\n  \u2514\u2500 Flexible executor implementations\n\n\u2713 Extensibility\n  \u251c\u2500 Easy to add new permanences\n  \u251c\u2500 Easy to add new processes\n  \u251c\u2500 Optional lifecycle hooks\n  \u2514\u2500 Plugin architecture ready\n\n\u2713 Maintainability\n  \u251c\u2500 Single responsibility per class\n  \u251c\u2500 Clear dependencies\n  \u251c\u2500 Well-defined interfaces\n  \u2514\u2500 Structured lifecycle\n\n\u2713 Flexibility\n  \u251c\u2500 Swap executor implementations\n  \u251c\u2500 Optional visualization\n  \u251c\u2500 WandB sweep support\n  \u2514\u2500 Nested progress bars\n</code></pre>"},{"location":"generated/architecture_diagram/#progressive-enhancement-helper-layer","title":"Progressive Enhancement: Helper Layer","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         HELPER LAYER (NEW!)                                 \u2502\n\u2502                         (helpers.py, decorators.py)                         \u2502\n\u2502                                                                             \u2502\n\u2502  Bridges the gap between scripts and pipelines                              \u2502\n\u2502  Works standalone OR with pipeline context                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  SCRIPT MODE (Standalone)             \u2502         PIPELINE MODE\n                                       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  # researcher_script.py         \u2502    \u2502    \u2502  # Within PipelineExecutor   \u2502\n\u2502                                 \u2502    \u2502    \u2502                              \u2502\n\u2502  from helpers import (          \u2502    \u2502    \u2502  # Set context               \u2502\n\u2502      progress_bar,              \u2502    \u2502    \u2502  set_pipeline_context({      \u2502\n\u2502      logger,                    \u2502    \u2502    \u2502      \"progress_manager\": pm, \u2502\n\u2502      device_manager             \u2502    \u2502    \u2502      \"wandb_logger\": wb,     \u2502\n\u2502  )                              \u2502    \u2502    \u2502      \"device\": dev           \u2502\n\u2502                                 \u2502    \u2502    \u2502  })                          \u2502\n\u2502  # Works without pipeline!      \u2502    \u2502    \u2502                              \u2502\n\u2502  logger.init(project=\"exp\")     \u2502    \u2502    \u2502  # Helpers auto-detect       \u2502\n\u2502                                 \u2502    \u2502    \u2502  # pipeline and use it       \u2502\n\u2502  for epoch in progress_bar(...):\u2502    \u2502    \u2502                              \u2502\n\u2502      device = device_manager    \u2502    \u2502    \u2502  # Same code works!          \u2502\n\u2502          .get_device()          \u2502    \u2502    \u2502  for epoch in progress_bar():\u2502\n\u2502      logger.log({\"loss\": loss}) \u2502    \u2502    \u2502      device = device_manager \u2502\n\u2502                                 \u2502    \u2502    \u2502          .get_device()       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502      logger.log({...})       \u2502\n                                       \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         Uses Rich &amp; basic WandB       \u2502       Uses Pipeline's permanences\n\n\nDECORATOR PATTERN: Function \u2192 Process\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  @pipeline_process                     # Marks function as pipeline-ready  \u2502\n\u2502  def train(epochs: int = 10):         # Parameters become config options   \u2502\n\u2502      '''Can run standalone OR in pipeline!'''                              \u2502\n\u2502                                                                            \u2502\n\u2502      device = device_manager.get_device()  # Works in both modes           \u2502\n\u2502      model = MyModel().to(device)                                          \u2502\n\u2502                                                                            \u2502\n\u2502      for epoch in progress_bar(range(epochs), desc=\"Training\"):            \u2502\n\u2502          loss = train_step(model)                                          \u2502\n\u2502          logger.log({\"loss\": loss})                                        \u2502\n\u2502                                                                            \u2502\n\u2502  # Run as script                                                           \u2502\n\u2502  if __name__ == \"__main__\":                                                \u2502\n\u2502      train(epochs=5)  # \u2190 Normal function call                             \u2502\n\u2502                                                                            \u2502\n\u2502  # Or in config.toml for pipeline                                          \u2502\n\u2502  # [processes.training]                                                    \u2502\n\u2502  # type = \"train\"                                                          \u2502\n\u2502  # params = { epochs = 10 }                                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\nHELPER IMPLEMENTATIONS\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  progress_bar(iterable, desc=\"Processing\")                                 \u2502\n\u2502    \u251c\u2500 No pipeline context: Uses rich.track (tqdm-like)                     \u2502\n\u2502    \u2514\u2500 With pipeline context: Uses pipeline's ProgressManager               \u2502\n\u2502                                                                            \u2502\n\u2502  logger.init(project, entity) / logger.log(metrics)                        \u2502\n\u2502    \u251c\u2500 No pipeline context: Initializes WandB manually                      \u2502\n\u2502    \u2514\u2500 With pipeline context: Uses pipeline's WandBManager                  \u2502\n\u2502                                                                            \u2502\n\u2502  device_manager.get_device()                                               \u2502\n\u2502    \u251c\u2500 No pipeline context: Selects first available GPU                     \u2502\n\u2502    \u2514\u2500 With pipeline context: Uses pipeline's Device permanence             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#research-to-production-journey","title":"Research-to-Production Journey","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    FROM SCRIPT TO PIPELINE                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nLevel 0: Raw Script                     Changes: 0\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  for epoch in range(10):       \u2502      \u2022 No framework\n\u2502      loss = train()            \u2502      \u2022 Manual everything\n\u2502      print(loss)               \u2502      \u2022 Hard to track\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            \u2502 Add 1 import, wrap loops\n            \u25bc\n\nLevel 1: Progress Bars                  Changes: +2 lines\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  from helpers import             \u2502      \u2713 Visual progress\n\u2502      progress_bar                \u2502      \u2713 Time estimates\n\u2502                                  \u2502      \u2022 Still a script\n\u2502  for epoch in progress_bar(...): \u2502\n\u2502      loss = train()              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            \u2502 Add logger.init() and logger.log()\n            \u25bc\n\nLevel 2: Experiment Tracking             Changes: +3 lines\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  from helpers import             \u2502      \u2713 Progress bars\n\u2502      progress_bar, logger        \u2502      \u2713 WandB logging\n\u2502                                  \u2502      \u2713 Experiment tracking\n\u2502  logger.init(project=\"exp\")      \u2502      \u2022 Still a script\n\u2502                                  \u2502\n\u2502  for epoch in progress_bar(...): \u2502\n\u2502      loss = train()              \u2502\n\u2502      logger.log({\"loss\": loss})  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            \u2502 Add device_manager\n            \u25bc\n\nLevel 3: Device Management               Changes: +2 lines\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  from helpers import           \u2502      \u2713 Progress + logging\n\u2502      progress_bar, logger,     \u2502      \u2713 Auto device select\n\u2502      device_manager            \u2502      \u2713 Multi-GPU support\n\u2502                                \u2502      \u2022 Still a script\n\u2502  device = device_manager       \u2502\n\u2502      .get_device()             \u2502\n\u2502  model.to(device)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            \u2502 Extract functions, add decorator\n            \u25bc\n\nLevel 4: Reusable Functions              Changes: Extract to functions\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  @pipeline_process              \u2502      \u2713 All previous features\n\u2502  def train(epochs: int = 10):   \u2502      \u2713 Reusable code\n\u2502      device = device_manager    \u2502      \u2713 Type hints\n\u2502          .get_device()          \u2502      \u2713 Ready for pipeline\n\u2502      for epoch in progress_bar( \u2502      \u2022 Still runs as script\n\u2502          range(epochs)          \u2502\n\u2502      ):                         \u2502\n\u2502          loss = train_step()    \u2502\n\u2502          logger.log(...)        \u2502\n\u2502                                 \u2502\n\u2502  if __name__ == \"__main__\":     \u2502\n\u2502      train(epochs=5)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            \u2502 Create config, register in pipeline\n            \u25bc\n\nLevel 5: Full Pipeline                   Changes: Config file + class wrapper\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  # config.toml                 \u2502      \u2713 All previous features\n\u2502  [processes.training]          \u2502      \u2713 Config-driven\n\u2502  type = \"TrainingProcess\"      \u2502      \u2713 Permanence lifecycle\n\u2502  params = { epochs = 10 }      \u2502      \u2713 Production ready\n\u2502                                \u2502      \u2713 Team collaboration\n\u2502  # Run via CLI                 \u2502      \u2713 CI/CD integration\n\u2502  $ tipi run exp     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/architecture_diagram/#key-insight-copy-paste-compatibility","title":"Key Insight: Copy-Paste Compatibility","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              CODE REUSE BETWEEN LEVELS                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nTraining Logic (Same across levels!)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  def train_step(model, batch, device):                     \u2502\n\u2502      inputs, targets = batch                               \u2502\n\u2502      inputs = inputs.to(device)                            \u2502\n\u2502      targets = targets.to(device)                          \u2502\n\u2502                                                            \u2502\n\u2502      optimizer.zero_grad()                                 \u2502\n\u2502      outputs = model(inputs)                               \u2502\n\u2502      loss = criterion(outputs, targets)                    \u2502\n\u2502      loss.backward()                                       \u2502\n\u2502      optimizer.step()                                      \u2502\n\u2502                                                            \u2502\n\u2502      return loss.item()                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                 \u25bc                 \u25bc\n   Level 2-3          Level 4           Level 5\n   (Script)      (Function)          (Process)\n\n  Same code!    Same code!          Same code!\n  Just called   Just decorated      Just wrapped\n  directly      with @pipeline      in PipelineProcess\n                                    class\n\nNo rewriting needed - just progressive wrapping!\n</code></pre>"},{"location":"generated/architecture_diagram/#documentation-references","title":"Documentation References","text":"<ul> <li>Full Guide: See <code>docs/progressive_enhancement.md</code></li> <li>Helper API: See <code>tipi/helpers.py</code></li> <li>Decorators: See <code>tipi/decorators.py</code></li> </ul>"},{"location":"generated/cli_enhancements/","title":"CLI Enhancement Summary","text":""},{"location":"generated/cli_enhancements/#overview","title":"Overview","text":"<p>The CLI has been significantly enhanced to support the research-to-production workflow with modular pipeline projects.</p>"},{"location":"generated/cli_enhancements/#new-commands","title":"New Commands","text":""},{"location":"generated/cli_enhancements/#1-run-updated","title":"1. <code>run</code> (Updated)","text":"<ul> <li>Renamed from <code>build_pipeline</code> to <code>run</code></li> <li>Added <code>--config</code> option for custom config files</li> <li>Better error messages with Rich formatting</li> </ul>"},{"location":"generated/cli_enhancements/#2-list-new","title":"2. <code>list</code> (New)","text":"<ul> <li>Lists all available pipelines</li> <li>Shows pipeline type (Built-in vs Linked)</li> <li>Displays config status</li> <li>Optional verbose mode (<code>-v</code>) shows component counts</li> <li>Optional <code>--links</code> flag shows symlink sources</li> <li>Rich table formatting</li> </ul>"},{"location":"generated/cli_enhancements/#3-inspect-new","title":"3. <code>inspect</code> (New)","text":"<ul> <li>Detailed component inspection</li> <li>Shows all permanences and processes</li> <li>Tree view visualization</li> <li>Optional docstring display (<code>--docs</code>)</li> <li>Shows config file location and status</li> </ul>"},{"location":"generated/cli_enhancements/#4-create-new","title":"4. <code>create</code> (New)","text":"<ul> <li>Creates standalone pipeline projects</li> <li>Generates complete project structure</li> <li>Includes pyproject.toml, README, .gitignore</li> <li>Optional example implementations (<code>--example</code>)</li> <li>Custom location support (<code>--location</code>)</li> </ul>"},{"location":"generated/cli_enhancements/#5-add-new","title":"5. <code>add</code> (New)","text":"<ul> <li>Links local projects as subpackages</li> <li>Clones from git repositories</li> <li>Creates symlinks in pipelines directory</li> <li>Supports SSH and HTTPS git URLs</li> <li>Branch selection for git repos (<code>--branch</code>)</li> <li>Custom clone location (<code>--location</code>)</li> <li>Validates package structure</li> </ul>"},{"location":"generated/cli_enhancements/#6-remove-new","title":"6. <code>remove</code> (New)","text":"<ul> <li>Removes linked subpackages</li> <li>Safely unlinks symlinks</li> <li>Optional source deletion (<code>--delete-source</code>)</li> <li>Safety checks for built-in pipelines</li> <li>Only deletes cloned repos in submodules/</li> </ul>"},{"location":"generated/cli_enhancements/#7-validate-new","title":"7. <code>validate</code> (New)","text":"<ul> <li>Validates pipeline configuration</li> <li>Checks module imports</li> <li>Validates class inheritance</li> <li>Checks TOML syntax</li> <li>Verifies config sections</li> <li>Clear success/failure reporting</li> </ul>"},{"location":"generated/cli_enhancements/#workflow-support","title":"Workflow Support","text":""},{"location":"generated/cli_enhancements/#creating-new-projects","title":"Creating New Projects","text":"<pre><code># Create standalone project\ntipi create my_pipeline --example\n\n# Project structure created:\nmy_pipeline/\n\u251c\u2500\u2500 my_pipeline/              # Package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 permanences.py\n\u2502   \u2514\u2500\u2500 processes.py\n\u251c\u2500\u2500 configs/\n\u2502   \u2514\u2500\u2500 pipeline_config.toml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 .gitignore\n</code></pre>"},{"location":"generated/cli_enhancements/#adding-projects","title":"Adding Projects","text":"<pre><code># Link local project\ntipi add ./my_pipeline\n\n# Clone from git\ntipi add https://github.com/user/pipeline.git\n\n# Creates symlink:\n# tipi/pipelines/my_pipeline -&gt; source\n</code></pre>"},{"location":"generated/cli_enhancements/#managing-projects","title":"Managing Projects","text":"<pre><code># List all\ntipi list -v\n\n# Inspect specific\ntipi inspect my_pipeline --docs\n\n# Validate\ntipi validate my_pipeline\n\n# Run\ntipi run my_pipeline\n\n# Remove\ntipi remove my_pipeline\n</code></pre>"},{"location":"generated/cli_enhancements/#file-generators","title":"File Generators","text":""},{"location":"generated/cli_enhancements/#_generate_project_init","title":"<code>_generate_project_init()</code>","text":"<p>Creates package <code>__init__.py</code> with:</p> <ul> <li>Component registration dictionaries</li> <li>Version information</li> <li>Proper imports</li> </ul>"},{"location":"generated/cli_enhancements/#_generate_permanence_file","title":"<code>_generate_permanence_file()</code>","text":"<p>Creates <code>permanences.py</code> with:</p> <ul> <li>Base imports</li> <li>Example permanence class (optional)</li> <li>Template comments</li> <li>Lifecycle methods</li> </ul>"},{"location":"generated/cli_enhancements/#_generate_processes_file","title":"<code>_generate_processes_file()</code>","text":"<p>Creates <code>processes.py</code> with:</p> <ul> <li>Base imports</li> <li>Example process class (optional)</li> <li>Template comments</li> <li>Execute and skip methods</li> </ul>"},{"location":"generated/cli_enhancements/#_generate_config_file","title":"<code>_generate_config_file()</code>","text":"<p>Creates TOML config with:</p> <ul> <li>Permanence definitions</li> <li>Process definitions</li> <li>Example configurations (optional)</li> <li>Inline comments</li> </ul>"},{"location":"generated/cli_enhancements/#_generate_readme","title":"<code>_generate_readme()</code>","text":"<p>Creates project README with:</p> <ul> <li>Structure overview</li> <li>Installation instructions</li> <li>Usage examples</li> <li>Development guide</li> </ul>"},{"location":"generated/cli_enhancements/#_generate_pyproject","title":"<code>_generate_pyproject()</code>","text":"<p>Creates <code>pyproject.toml</code> with:</p> <ul> <li>Package metadata</li> <li>Dependencies</li> <li>Development dependencies</li> <li>Ruff configuration</li> <li>Build system setup</li> </ul>"},{"location":"generated/cli_enhancements/#_generate_gitignore","title":"<code>_generate_gitignore()</code>","text":"<p>Creates <code>.gitignore</code> with:</p> <ul> <li>Python artifacts</li> <li>Virtual environments</li> <li>IDE files</li> <li>Testing artifacts</li> <li>OS files</li> </ul>"},{"location":"generated/cli_enhancements/#rich-formatting","title":"Rich Formatting","text":"<p>All commands use Rich library for beautiful output:</p> <ul> <li>Tables: List command with colored columns</li> <li>Trees: Inspect command with hierarchical view</li> <li>Panels: Success/error messages with borders</li> <li>Colors: Semantic coloring (green=success, red=error, yellow=warning)</li> <li>Console: Consistent formatting throughout</li> </ul>"},{"location":"generated/cli_enhancements/#safety-features","title":"Safety Features","text":""},{"location":"generated/cli_enhancements/#link-management","title":"Link Management","text":"<ul> <li>Validates package structure before linking</li> <li>Checks for naming conflicts</li> <li>Confirms before overwriting links</li> <li>Distinguishes between built-in and linked pipelines</li> </ul>"},{"location":"generated/cli_enhancements/#source-deletion","title":"Source Deletion","text":"<ul> <li>Only deletes sources in <code>submodules/</code> directory</li> <li>Requires explicit <code>--delete-source</code> flag</li> <li>Interactive confirmation before deletion</li> <li>Prevents accidental deletion of external projects</li> </ul>"},{"location":"generated/cli_enhancements/#validation","title":"Validation","text":"<ul> <li>Module import checking</li> <li>Class inheritance validation</li> <li>TOML syntax verification</li> <li>Config section requirements</li> <li>Detailed error reporting</li> </ul>"},{"location":"generated/cli_enhancements/#integration-with-progressive-enhancement","title":"Integration with Progressive Enhancement","text":"<p>The CLI now supports the Level 5 workflow:</p> <pre><code>Level 4: Functions          Level 5: Full Pipeline\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@pipeline_process     \u2192    tipi create my_pipeline\ndef train():          \u2192    Edit permanences.py &amp; processes.py\n    ...               \u2192    Update config.toml\n                      \u2192    tipi add ./my_pipeline\nRun as script         \u2192    tipi run my_pipeline\n</code></pre>"},{"location":"generated/cli_enhancements/#example-workflows","title":"Example Workflows","text":""},{"location":"generated/cli_enhancements/#researcher-creates-new-pipeline","title":"Researcher Creates New Pipeline","text":"<pre><code># Day 1: Create project\ntipi create research_pipeline --example\ncd research_pipeline\n\n# Day 2-7: Develop (edit files)\n# Edit research_pipeline/permanences.py\n# Edit research_pipeline/processes.py\n# Edit configs/pipeline_config.toml\n\n# Week 2: Link to main pipeline\ncd /path/to/TensorImgPipeline\ntipi add ../research_pipeline\n\n# Validate and run\ntipi validate research_pipeline\ntipi run research_pipeline\n</code></pre>"},{"location":"generated/cli_enhancements/#team-member-uses-existing-pipeline","title":"Team Member Uses Existing Pipeline","text":"<pre><code># Clone from team repo\ntipi add https://github.com/team/ml-pipeline.git\n\n# Inspect what it does\ntipi inspect ml-pipeline --docs\n\n# Run it\ntipi validate ml-pipeline\ntipi run ml-pipeline\n</code></pre>"},{"location":"generated/cli_enhancements/#cleanup-old-projects","title":"Cleanup Old Projects","text":"<pre><code># List all pipelines\ntipi list -v\n\n# Remove old one (keep source)\ntipi remove old_pipeline\n\n# Remove cloned repo (delete source)\ntipi remove temp_pipeline --delete-source\n</code></pre>"},{"location":"generated/cli_enhancements/#benefits","title":"Benefits","text":"<ol> <li>Modular: Projects are self-contained and reusable</li> <li>Flexible: Link local projects or clone from git</li> <li>Safe: Multiple validation and confirmation steps</li> <li>User-friendly: Rich formatting and clear messages</li> <li>Complete: Full project scaffolding</li> <li>Discoverable: List and inspect commands</li> <li>Maintainable: Easy to add/remove projects</li> </ol>"},{"location":"generated/cli_enhancements/#future-enhancements","title":"Future Enhancements","text":"<p>Possible future additions:</p> <ul> <li><code>tipi update &lt;name&gt;</code> - Update git-cloned packages</li> <li><code>tipi test &lt;name&gt;</code> - Run pipeline tests</li> <li><code>tipi export &lt;name&gt;</code> - Export pipeline as standalone package</li> <li><code>tipi template list</code> - Show available templates</li> <li><code>tipi template create &lt;name&gt;</code> - Create custom templates</li> <li>Auto-completion support</li> <li>Configuration validation with JSON schema</li> <li>Pipeline dependency resolution</li> <li>Version management</li> </ul>"},{"location":"generated/cli_enhancements/#documentation","title":"Documentation","text":"<p>Created documentation:</p> <ul> <li><code>docs/cli_reference.md</code> - Complete CLI reference</li> <li>Updated <code>docs/architecture_diagram.md</code> - Architecture overview</li> <li>Updated <code>docs/progressive_enhancement.md</code> - Level 5 workflow</li> </ul>"},{"location":"generated/cli_enhancements/#technical-details","title":"Technical Details","text":""},{"location":"generated/cli_enhancements/#symlink-management","title":"Symlink Management","text":"<ul> <li>Uses <code>Path.symlink_to()</code> for cross-platform compatibility</li> <li>Resolves symlinks with <code>Path.resolve()</code></li> <li>Checks symlink status with <code>Path.is_symlink()</code></li> </ul>"},{"location":"generated/cli_enhancements/#git-integration","title":"Git Integration","text":"<ul> <li>Uses <code>subprocess.run()</code> for git commands</li> <li>Supports HTTPS and SSH URLs</li> <li>Branch selection with <code>--branch</code> flag</li> <li>Error handling with stderr capture</li> </ul>"},{"location":"generated/cli_enhancements/#module-loading","title":"Module Loading","text":"<ul> <li>Uses <code>importlib.import_module()</code> for dynamic loading</li> <li>Handles ImportError gracefully</li> <li>Validates class inheritance with <code>issubclass()</code></li> <li>Accesses module attributes with <code>getattr()</code></li> </ul>"},{"location":"generated/cli_enhancements/#file-generation","title":"File Generation","text":"<ul> <li>Template strings with f-strings</li> <li>Conditional content based on flags</li> <li>Consistent formatting and style</li> <li>Includes comments and documentation</li> </ul>"},{"location":"generated/cli_reference/","title":"CLI Reference","text":"<p>Complete reference for the <code>tipi</code> command-line tool.</p>"},{"location":"generated/cli_reference/#overview","title":"Overview","text":"<p>The <code>tipi</code> CLI supports the complete workflow from creating new pipeline projects to running them in production.</p> <pre><code>tipi [COMMAND] [OPTIONS]\n</code></pre>"},{"location":"generated/cli_reference/#commands","title":"Commands","text":""},{"location":"generated/cli_reference/#run-execute-a-pipeline","title":"<code>run</code> - Execute a Pipeline","text":"<p>Run a pipeline by name.</p> <pre><code>tipi run PIPELINE_NAME [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PIPELINE_NAME</code> - Name of the pipeline to run (e.g., 'sam2segnet')</li> </ul> <p>Options:</p> <ul> <li><code>--config</code>, <code>-c</code> - Path to custom config file (relative to configs/)</li> </ul> <p>Examples:</p> <pre><code># Run default pipeline\ntipi run sam2segnet\n\n# Run with custom config\ntipi run my_pipeline --config custom.toml\n</code></pre>"},{"location":"generated/cli_reference/#list-list-available-pipelines","title":"<code>list</code> - List Available Pipelines","text":"<p>Show all available pipelines including linked subpackages.</p> <pre><code>tipi list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--verbose</code>, <code>-v</code> - Show detailed information (permanences and processes count)</li> <li><code>--links/--no-links</code> - Show/hide symlink source paths (default: show)</li> </ul> <p>Examples:</p> <pre><code># Simple list\ntipi list\n\n# Detailed view\ntipi list -v\n\n# Hide link sources\ntipi list --no-links\n</code></pre> <p>Output:</p> <ul> <li>Pipeline name</li> <li>Type (Built-in or Linked)</li> <li>Config status</li> <li>Status (Ready or Missing config)</li> <li>Permanences count (with <code>-v</code>)</li> <li>Processes count (with <code>-v</code>)</li> <li>Source path (for linked packages, with <code>--links</code>)</li> </ul>"},{"location":"generated/cli_reference/#inspect-inspect-pipeline-components","title":"<code>inspect</code> - Inspect Pipeline Components","text":"<p>Show detailed information about a pipeline's permanences and processes.</p> <pre><code>tipi inspect PIPELINE_NAME [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PIPELINE_NAME</code> - Name of the pipeline to inspect</li> </ul> <p>Options:</p> <ul> <li><code>--docs</code>, <code>-d</code> - Show docstrings for components</li> </ul> <p>Examples:</p> <pre><code># Basic inspection\ntipi inspect sam2segnet\n\n# With docstrings\ntipi inspect sam2segnet --docs\n</code></pre> <p>Output:</p> <ul> <li>Tree view of permanences and processes</li> <li>Class names and registration names</li> <li>Docstrings (with <code>--docs</code>)</li> <li>Config file location and status</li> </ul>"},{"location":"generated/cli_reference/#create-create-new-pipeline-project","title":"<code>create</code> - Create New Pipeline Project","text":"<p>Create a new standalone pipeline project with complete scaffolding.</p> <pre><code>tipi create PROJECT_NAME [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PROJECT_NAME</code> - Name for the new pipeline project</li> </ul> <p>Options:</p> <ul> <li><code>--location</code>, <code>-l</code> - Directory to create project in (default: current directory)</li> <li><code>--example</code>, <code>-e</code> - Include example permanence and process implementations</li> </ul> <p>Examples:</p> <pre><code># Create in current directory\ntipi create my_pipeline\n\n# Create in specific location\ntipi create my_pipeline --location ./projects\n\n# Create with examples\ntipi create my_pipeline --example\n</code></pre> <p>Creates:</p> <pre><code>my_pipeline/\n\u251c\u2500\u2500 my_pipeline/\n\u2502   \u251c\u2500\u2500 __init__.py           # Component registration\n\u2502   \u251c\u2500\u2500 permanences.py        # Permanence implementations\n\u2502   \u2514\u2500\u2500 processes.py          # Process implementations\n\u251c\u2500\u2500 configs/\n\u2502   \u2514\u2500\u2500 pipeline_config.toml  # Configuration file\n\u251c\u2500\u2500 pyproject.toml            # Package metadata\n\u251c\u2500\u2500 README.md                 # Documentation\n\u2514\u2500\u2500 .gitignore               # Git ignore rules\n</code></pre>"},{"location":"generated/cli_reference/#add-link-or-clone-pipeline-package","title":"<code>add</code> - Link or Clone Pipeline Package","text":"<p>Link an existing local project or clone from a git repository as a subpackage.</p> <pre><code>tipi add SOURCE [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>SOURCE</code> - Local path to project OR git repository URL</li> </ul> <p>Options:</p> <ul> <li><code>--name</code>, <code>-n</code> - Name for the linked pipeline (defaults to directory name)</li> <li><code>--location</code>, <code>-l</code> - Location to clone git repos (default: ./submodules)</li> <li><code>--branch</code>, <code>-b</code> - Git branch to checkout when cloning</li> </ul> <p>Examples:</p> <pre><code># Link local project\ntipi add ./my_pipeline_project\ntipi add /path/to/project --name custom_name\n\n# Clone from git (HTTPS)\ntipi add https://github.com/user/ml-pipeline.git\n\n# Clone from git (SSH)\ntipi add git@github.com:user/pipeline.git\n\n# Clone specific branch\ntipi add https://github.com/user/repo.git --branch dev\n\n# Clone to custom location\ntipi add https://github.com/user/pipeline.git --location ./external\n</code></pre> <p>Behavior:</p> <ul> <li>Local path: Creates a symlink in the projects directory (development: <code>tipi/pipelines/</code>, production: <code>~/.config/tipi/projects/</code>)</li> <li>Git URL: Clones to specified location (or cache directory), then creates symlink</li> <li>Validates package structure (must have <code>__init__.py</code>)</li> <li>Checks for naming conflicts</li> <li>Confirms before overwriting existing links</li> </ul>"},{"location":"generated/cli_reference/#remove-remove-linked-package","title":"<code>remove</code> - Remove Linked Package","text":"<p>Remove a linked subpackage from the pipeline system.</p> <pre><code>tipi remove PIPELINE_NAME [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PIPELINE_NAME</code> - Name of the linked pipeline to remove</li> </ul> <p>Options:</p> <ul> <li><code>--delete-source</code> - Also delete the source directory (only safe for cloned repos in submodules/)</li> </ul> <p>Examples:</p> <pre><code># Just remove the link\ntipi remove my_pipeline\n\n# Remove link and delete source (if in submodules/)\ntipi remove my_pipeline --delete-source\n</code></pre> <p>Safety:</p> <ul> <li>Built-in pipelines cannot be removed</li> <li>Source deletion only works for packages in cache directory</li> <li>Confirms before deleting source directories</li> </ul>"},{"location":"generated/cli_reference/#validate-validate-pipeline-configuration","title":"<code>validate</code> - Validate Pipeline Configuration","text":"<p>Check that a pipeline is properly configured and ready to run.</p> <pre><code>tipi validate PIPELINE_NAME\n</code></pre> <p>Arguments:</p> <ul> <li><code>PIPELINE_NAME</code> - Name of the pipeline to validate</li> </ul> <p>Examples:</p> <pre><code>tipi validate sam2segnet\n</code></pre> <p>Checks:</p> <ul> <li>\u2713 Pipeline module exists and is importable</li> <li>\u2713 Permanences and processes are registered</li> <li>\u2713 Registered classes inherit from correct base classes</li> <li>\u2713 Config file exists and is valid TOML</li> <li>\u2713 Config has required sections (permanences/processes)</li> </ul> <p>Output:</p> <ul> <li>Green panel if all checks pass</li> <li>Red panel with issues if validation fails</li> </ul>"},{"location":"generated/cli_reference/#info-show-installation-information","title":"<code>info</code> - Show Installation Information","text":"<p>Display information about the current TensorImgPipeline installation and configuration.</p> <pre><code>tipi info\n</code></pre> <p>Examples:</p> <pre><code>tipi info\n</code></pre> <p>Output:</p> <ul> <li>Projects directory path (where pipelines are loaded from)</li> <li>Configs directory path (where configuration files are stored)</li> <li>Cache directory path (for cloned repositories)</li> <li>User config directory (~/.config/tipi)</li> <li>Directory existence status</li> </ul> <p>Default Paths:</p> <ul> <li>Projects: <code>~/.config/tipi/projects/</code></li> <li>Configs: <code>~/.config/tipi/configs/</code></li> <li>Cache: <code>~/.cache/tipi/</code></li> </ul> <p>Use Cases:</p> <ul> <li>Debugging path issues</li> <li>Understanding where to place pipeline projects</li> <li>Checking directory structure before adding pipelines</li> </ul>"},{"location":"generated/cli_reference/#complete-workflow-example","title":"Complete Workflow Example","text":""},{"location":"generated/cli_reference/#starting-from-scratch","title":"Starting from Scratch","text":"<pre><code># 1. Create a new pipeline project\ntipi create my_ml_pipeline --example\n\n\n# 2. Navigate to the project\ncd my_ml_pipeline\n\n# 3. Edit components (in your editor)\n# - Edit my_ml_pipeline/permanences.py\n# - Edit my_ml_pipeline/processes.py\n# - Update configs/pipeline_config.toml\n\n# 4. Go back to main pipeline directory\ncd /path/to/TensorImgPipeline\n\n# 5. Link your project\ntipi add ../my_ml_pipeline\n\n# 6. Validate configuration\ntipi validate my_ml_pipeline\n\n# 7. Run the pipeline\ntipi run my_ml_pipeline\n</code></pre>"},{"location":"generated/cli_reference/#using-an-existing-git-repository","title":"Using an Existing Git Repository","text":"<pre><code># 1. Clone and link a pipeline from GitHub\ntipi add https://github.com/user/awesome-pipeline.git\n\n# 2. Check what was added\ntipi list -v\n\n# 3. Inspect the components\ntipi inspect awesome-pipeline --docs\n\n# 4. Validate before running\ntipi validate awesome-pipeline\n\n# 5. Run it\ntipi run awesome-pipeline\n</code></pre>"},{"location":"generated/cli_reference/#managing-multiple-pipelines","title":"Managing Multiple Pipelines","text":"<pre><code># List all pipelines\ntipi list -v\n\n# Inspect each one\ntipi inspect pipeline1\ntipi inspect pipeline2\n\n# Run specific ones\ntipi run pipeline1\ntipi run pipeline2 --config custom.toml\n\n# Remove one that's no longer needed\ntipi remove old_pipeline\n</code></pre>"},{"location":"generated/cli_reference/#configuration-files","title":"Configuration Files","text":""},{"location":"generated/cli_reference/#project-structure","title":"Project Structure","text":"<p>When you create a pipeline with <code>create</code>, you get this structure:</p> <pre><code>my_pipeline/\n\u251c\u2500\u2500 my_pipeline/              # Python package\n\u2502   \u251c\u2500\u2500 __init__.py          # Registers components\n\u2502   \u251c\u2500\u2500 permanences.py       # Permanence classes\n\u2502   \u2514\u2500\u2500 processes.py         # Process classes\n\u251c\u2500\u2500 configs/                 # Configuration directory\n\u2502   \u2514\u2500\u2500 pipeline_config.toml # Pipeline configuration\n\u251c\u2500\u2500 pyproject.toml           # Package metadata\n\u251c\u2500\u2500 README.md               # Documentation\n\u2514\u2500\u2500 .gitignore             # Git ignore rules\n</code></pre>"},{"location":"generated/cli_reference/#configuration-file-format","title":"Configuration File Format","text":"<p><code>configs/pipeline_config.toml</code>:</p> <pre><code># Define permanences\n[permanences.device]\ntype = \"Device\"  # Class name from __init__.py\n\n[permanences.network]\ntype = \"Network\"\nparams = { model = \"resnet50\", num_classes = 10 }\n\n# Define processes\n[processes.training]\ntype = \"TrainingProcess\"\nparams = { epochs = 10, learning_rate = 0.001 }\n\n[processes.validation]\ntype = \"ValidationProcess\"\n</code></pre>"},{"location":"generated/cli_reference/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>TIPI_CONFIG_DIR</code> - Override configs directory</li> <li><code>TIPI_PROJECTS_DIR</code> - Override projects directory</li> <li><code>TIPI_CACHE_DIR</code> - Override cache directory</li> </ul> <p>Note: Environment variables are primarily for testing and creating isolated test scenarios.</p>"},{"location":"generated/cli_reference/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"generated/cli_reference/#quick-inspection","title":"Quick Inspection","text":"<pre><code># Combine list and inspect for quick overview\ntipi list -v &amp;&amp; tipi inspect sam2segnet\n</code></pre>"},{"location":"generated/cli_reference/#development-workflow","title":"Development Workflow","text":"<pre><code># During development, frequently validate\ntipi validate my_pipeline &amp;&amp; tipi run my_pipeline\n</code></pre>"},{"location":"generated/cli_reference/#working-with-git-repos","title":"Working with Git Repos","text":"<pre><code># Clone, inspect, then run\ntipi add https://github.com/user/pipeline.git &amp;&amp; \\\n  tipi inspect pipeline --docs &amp;&amp; \\\n  tipi validate pipeline\n</code></pre>"},{"location":"generated/cli_reference/#batch-operations","title":"Batch Operations","text":"<pre><code># Validate all pipelines\nfor pipeline in $(tipi list --no-links | tail -n +3 | awk '{print $1}'); do\n    echo \"Validating $pipeline...\"\n    tipi validate $pipeline\ndone\n</code></pre>"},{"location":"generated/cli_reference/#troubleshooting","title":"Troubleshooting","text":""},{"location":"generated/cli_reference/#pipeline-not-found","title":"\"Pipeline not found\"","text":"<ul> <li>Check <code>tipi list</code> to see available pipelines</li> <li>Use <code>tipi info</code> to verify your paths</li> <li>Check that pipelines are in <code>~/.config/tipi/projects/</code></li> <li>For linked packages, verify the symlink exists in the projects directory</li> </ul>"},{"location":"generated/cli_reference/#missing-config","title":"\"Missing config\"","text":"<ul> <li>Create or update configs in the configs directory (use <code>tipi info</code> to see path)</li> <li>Default location: <code>~/.config/tipi/configs/&lt;pipeline_name&gt;/pipeline_config.toml</code></li> <li>Check the config file path with <code>tipi inspect &lt;pipeline&gt;</code></li> </ul>"},{"location":"generated/cli_reference/#invalid-toml","title":"\"Invalid TOML\"","text":"<ul> <li>Validate your TOML syntax</li> <li>Ensure proper quoting of strings</li> <li>Check for matching braces in inline tables</li> </ul>"},{"location":"generated/cli_reference/#module-not-found","title":"\"Module not found\"","text":"<ul> <li>Ensure package has <code>__init__.py</code></li> <li>Check that permanences/processes are properly imported in <code>__init__.py</code></li> <li>Verify the symlink points to the correct directory</li> </ul>"},{"location":"generated/cli_reference/#git-clone-fails","title":"Git clone fails","text":"<ul> <li>Check your internet connection</li> <li>Verify repository URL</li> <li>Ensure you have access rights (for private repos)</li> <li>Try SSH if HTTPS fails (or vice versa)</li> </ul>"},{"location":"generated/cli_reference/#see-also","title":"See Also","text":"<ul> <li>Progressive Enhancement Guide - From scripts to pipelines</li> <li>Architecture Diagram - System architecture</li> <li>Getting Started - First steps with the pipeline</li> </ul>"},{"location":"generated/improvements_summary/","title":"Architecture Improvements for Research Workflow","text":""},{"location":"generated/improvements_summary/#problem-statement","title":"Problem Statement","text":"<p>The original architecture required too much upfront structure:</p> <ul> <li>Define Permanence/Process classes</li> <li>Create TOML configs</li> <li>Register everything in builder</li> <li>Go through CLI/runner</li> </ul> <p>This creates friction for researchers who just want to experiment!</p>"},{"location":"generated/improvements_summary/#solution-progressive-enhancement-architecture","title":"Solution: Progressive Enhancement Architecture","text":""},{"location":"generated/improvements_summary/#core-principle","title":"Core Principle","text":"<p>\"Start simple, scale when needed\"</p> <p>Researchers can:</p> <ol> <li>Start with plain Python scripts</li> <li>Add features incrementally (progress bars \u2192 logging \u2192 device management)</li> <li>Extract to functions when code stabilizes</li> <li>Convert to pipeline only when going to production</li> </ol>"},{"location":"generated/improvements_summary/#new-components","title":"New Components","text":""},{"location":"generated/improvements_summary/#1-helper-module-helperspy","title":"1. Helper Module (<code>helpers.py</code>)","text":"<p>Provides script-level utilities that work standalone OR with pipeline:</p> <pre><code>from tipi.helpers import progress_bar, logger, device_manager\n\n# Works in plain scripts!\nfor epoch in progress_bar(range(10)):\n    device = device_manager.get_device()\n    loss = train()\n    logger.log({\"loss\": loss})\n</code></pre> <p>Key Features:</p> <ul> <li><code>progress_bar()</code>: tqdm-like progress bars (uses Rich standalone, pipeline's ProgressManager when available)</li> <li><code>logger</code>: WandB logging (initializes manually or uses pipeline's WandBManager)</li> <li><code>device_manager</code>: Smart GPU selection (simple selection standalone, uses pipeline's Device when available)</li> </ul> <p>How it works:</p> <ul> <li>Checks global <code>_pipeline_context</code> to detect if running in pipeline</li> <li>If context exists, uses pipeline permanences</li> <li>If not, provides standalone implementations</li> </ul>"},{"location":"generated/improvements_summary/#2-decorator-module-decoratorspy","title":"2. Decorator Module (<code>decorators.py</code>)","text":"<p>Makes functions pipeline-ready with zero code changes:</p> <pre><code>from tipi.decorators import pipeline_process\n\n@pipeline_process\ndef train(epochs: int = 10):\n    \"\"\"This function works standalone AND in pipeline!\"\"\"\n    for epoch in helpers.progress_bar(range(epochs)):\n        loss = train_step()\n        helpers.logger.log({\"loss\": loss})\n\n# Run as script\nif __name__ == \"__main__\":\n    train(epochs=5)\n\n# Or register in pipeline config:\n# [processes.training]\n# type = \"train\"\n# params = { epochs = 10 }\n</code></pre> <p>Key Features:</p> <ul> <li>Decorated functions remain callable as normal functions</li> <li>Decorator creates a <code>PipelineProcess</code> class dynamically</li> <li>Function parameters become config parameters</li> <li>Automatic pipeline context injection</li> </ul>"},{"location":"generated/improvements_summary/#3-progressive-enhancement-guide-docsprogressive_enhancementmd","title":"3. Progressive Enhancement Guide (<code>docs/progressive_enhancement.md</code>)","text":"<p>Complete guide showing 5 levels of enhancement:</p> <ul> <li>Level 0: Raw script</li> <li>Level 1: Add progress bars (+2 lines)</li> <li>Level 2: Add logging (+3 lines)</li> <li>Level 3: Better device management (+2 lines)</li> <li>Level 4: Extract to reusable functions</li> <li>Level 5: Full pipeline (config file + class wrapper)</li> </ul> <p>Each level adds ONE concept, building on previous levels.</p>"},{"location":"generated/improvements_summary/#architecture-changes","title":"Architecture Changes","text":""},{"location":"generated/improvements_summary/#before-original-proposed","title":"Before (Original Proposed)","text":"<pre><code>CLI \u2192 Runner \u2192 Builder \u2192 Controller \u2192 Executor \u2192 Processes\n                                                      \u2191\n                                              Requires class definition\n                                              Requires TOML config\n                                              Requires registration\n</code></pre> <p>Entry barrier: HIGH (must understand entire pipeline)</p>"},{"location":"generated/improvements_summary/#after-with-progressive-enhancement","title":"After (With Progressive Enhancement)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Script Mode                                        \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2502\n\u2502  Plain Python \u2192 helpers.py (standalone mode)        \u2502\n\u2502                                                     \u2502\n\u2502  Entry barrier: ZERO (just import helpers)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u2502 (when ready)\n                      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Hybrid Mode                                        \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2502\n\u2502  Functions + @pipeline_process \u2192 helpers (dual)     \u2502\n\u2502                                                     \u2502\n\u2502  Entry barrier: LOW (add decorator)                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u2502 (when productionizing)\n                      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Pipeline Mode                                      \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2502\n\u2502  CLI \u2192 Runner \u2192 Builder \u2192 Controller \u2192 Executor     \u2502\n\u2502                                    \u2193                \u2502\n\u2502                            Processes \u2192 helpers      \u2502\n\u2502                                    (pipeline mode)  \u2502\n\u2502                                                     \u2502\n\u2502  Entry barrier: MEDIUM (config + classes)           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"generated/improvements_summary/#technical-implementation","title":"Technical Implementation","text":""},{"location":"generated/improvements_summary/#pipeline-context-injection","title":"Pipeline Context Injection","text":"<p>The <code>PipelineExecutor</code> sets context before running processes:</p> <pre><code>class PipelineExecutor:\n    def _run_processes(self):\n        # Set context for helpers\n        from tipi.helpers import set_pipeline_context\n\n        context = {\n            \"progress_manager\": self.controller.get_permanence(\"progress_manager\", None),\n            \"wandb_logger\": self.controller.get_permanence(\"wandb_logger\", None),\n            \"device\": self.controller.get_permanence(\"device\", None),\n        }\n        set_pipeline_context(context)\n\n        try:\n            # Run processes (they use helpers which now see the context)\n            for process in self.controller.iterate_processes():\n                process.execute()\n        finally:\n            clear_pipeline_context()\n</code></pre>"},{"location":"generated/improvements_summary/#helper-auto-detection","title":"Helper Auto-Detection","text":"<p>Each helper checks for pipeline context:</p> <pre><code>def progress_bar(iterable, desc=\"Processing\"):\n    # Check if running in pipeline\n    if _pipeline_context:\n        progress_manager = _pipeline_context.get(\"progress_manager\")\n        if progress_manager:\n            # Use pipeline's progress manager\n            return pipeline_progress(iterable, desc, progress_manager)\n\n    # Fallback to rich.track (tqdm-like)\n    return track(iterable, description=desc)\n</code></pre>"},{"location":"generated/improvements_summary/#function-to-process-conversion","title":"Function-to-Process Conversion","text":"<p>The <code>@pipeline_process</code> decorator dynamically creates a <code>PipelineProcess</code> class:</p> <pre><code>@pipeline_process\ndef train(epochs: int = 10):\n    # Function body...\n    pass\n\n# Decorator generates:\nclass TrainProcess(PipelineProcess):\n    def __init__(self, controller, force=False, epochs=10):\n        self.controller = controller\n        self.epochs = epochs\n\n    def execute(self):\n        set_pipeline_context({...})\n        try:\n            return train(epochs=self.epochs)  # Call original function\n        finally:\n            clear_pipeline_context()\n</code></pre>"},{"location":"generated/improvements_summary/#benefits","title":"Benefits","text":""},{"location":"generated/improvements_summary/#for-researchers","title":"For Researchers","text":"<ol> <li>Zero friction start: Just write normal Python</li> <li>Incremental enhancement: Add features one at a time</li> <li>No forced migration: Can stay at any level</li> <li>Copy-paste friendly: Code works across levels</li> <li>Familiar tools: tqdm-like progress bars, standard WandB</li> </ol>"},{"location":"generated/improvements_summary/#for-production","title":"For Production","text":"<ol> <li>Full pipeline features: When needed</li> <li>Config-driven: Easy to manage experiments</li> <li>Testable: Each level is testable</li> <li>Team collaboration: Standardized structure</li> <li>CI/CD ready: CLI integration</li> </ol>"},{"location":"generated/improvements_summary/#for-both","title":"For Both","text":"<ol> <li>Same code: Training logic doesn't change between levels</li> <li>Progressive complexity: Match tool to task</li> <li>Smooth transition: No rewrites needed</li> <li>Dual-mode helpers: Work everywhere</li> </ol>"},{"location":"generated/improvements_summary/#migration-path","title":"Migration Path","text":""},{"location":"generated/improvements_summary/#existing-scripts-enhanced-scripts","title":"Existing Scripts \u2192 Enhanced Scripts","text":"<pre><code># Before\nfor epoch in range(10):\n    loss = train()\n    print(loss)\n\n# After (add 3 lines)\nfrom tipi.helpers import progress_bar, logger\nlogger.init(project=\"exp\")\n\nfor epoch in progress_bar(range(10)):\n    loss = train()\n    logger.log({\"loss\": loss})\n</code></pre>"},{"location":"generated/improvements_summary/#enhanced-scripts-pipeline-ready-functions","title":"Enhanced Scripts \u2192 Pipeline-Ready Functions","text":"<pre><code># Add decorator (1 line)\n@pipeline_process\ndef train(epochs: int = 10):\n    # Same code as before!\n    pass\n</code></pre>"},{"location":"generated/improvements_summary/#pipeline-ready-functions-full-pipeline","title":"Pipeline-Ready Functions \u2192 Full Pipeline","text":"<pre><code># Create config.toml\n[processes.training]\ntype = \"train\"  # Function name\nparams = { epochs = 10 }\n</code></pre>"},{"location":"generated/improvements_summary/#comparison-with-original-architecture","title":"Comparison with Original Architecture","text":"Aspect Original With Progressive Enhancement Entry point CLI/Runner Plain Python script Initial complexity High (classes + config) Zero (just helpers) Learning curve Steep Gradual Research workflow Forced into pipeline Natural script evolution Production workflow Ready Ready (same endpoint) Code reuse Medium High (same code everywhere) Testing Full pipeline only Each level testable Team onboarding Full architecture Start with helpers"},{"location":"generated/improvements_summary/#example-real-research-scenario","title":"Example: Real Research Scenario","text":""},{"location":"generated/improvements_summary/#week-1-new-idea","title":"Week 1: New idea","text":"<pre><code># quick_test.py\nfrom tipi.helpers import progress_bar\nfor epoch in progress_bar(range(5)):\n    print(train())\n</code></pre>"},{"location":"generated/improvements_summary/#week-2-looks-promising","title":"Week 2: Looks promising","text":"<pre><code># experiment_v1.py\nfrom tipi.helpers import progress_bar, logger\nlogger.init(project=\"new_idea\")\nfor epoch in progress_bar(range(10)):\n    logger.log({\"loss\": train()})\n</code></pre>"},{"location":"generated/improvements_summary/#week-3-multiple-variations","title":"Week 3: Multiple variations","text":"<pre><code># experiment_v2.py, v3.py, v4.py\n# All using helpers - easy to compare in WandB\n</code></pre>"},{"location":"generated/improvements_summary/#month-1-extract-common-logic","title":"Month 1: Extract common logic","text":"<pre><code># train_utils.py\n@pipeline_process\ndef train(learning_rate: float = 0.001):\n    # Shared logic\n    pass\n\n# experiment_v5.py\nfrom train_utils import train\ntrain(learning_rate=0.01)\n</code></pre>"},{"location":"generated/improvements_summary/#month-2-production","title":"Month 2: Production","text":"<pre><code># pipeline.toml\n[processes.training]\ntype = \"train\"\nparams = { learning_rate = 0.001 }\n</code></pre> <p>Same training code from Week 1 to Month 2!</p>"},{"location":"generated/improvements_summary/#implementation-status","title":"Implementation Status","text":""},{"location":"generated/improvements_summary/#completed","title":"Completed","text":"<ul> <li>\u2705 <code>helpers.py</code> module with progress_bar, logger, device_manager</li> <li>\u2705 <code>decorators.py</code> module with @pipeline_process</li> <li>\u2705 <code>docs/progressive_enhancement.md</code> full guide</li> <li>\u2705 Architecture diagrams updated</li> </ul>"},{"location":"generated/improvements_summary/#todo-for-full-implementation","title":"TODO (for full implementation)","text":"<ul> <li>[ ] Integrate helper context setting in PipelineExecutor</li> <li>[ ] Implement pipeline progress integration in helpers</li> <li>[ ] Add tests for dual-mode helpers</li> <li>[ ] Create example scripts at each level</li> <li>[ ] Update existing processes to use helpers</li> <li>[ ] Add CLI flag to detect pipeline mode</li> <li>[ ] Create migration guide for existing pipelines</li> </ul>"},{"location":"generated/improvements_summary/#questions-answers","title":"Questions &amp; Answers","text":"<p>Q: Does this change the core architecture? A: No, it adds a new entry layer. Full pipeline architecture remains unchanged.</p> <p>Q: Can existing pipelines use helpers? A: Yes! Processes can import helpers and they'll automatically use permanences.</p> <p>Q: What if someone doesn't want helpers? A: Completely optional. Original architecture still works.</p> <p>Q: Performance impact? A: Minimal. Context checking is a simple dict lookup.</p> <p>Q: Does this work with existing permanences? A: Yes! Helpers just access them through context.</p>"},{"location":"generated/improvements_summary/#recommendation","title":"Recommendation","text":"<p>Implement progressive enhancement in this order:</p> <ol> <li> <p>Phase 1: Helper module (standalone mode only)</p> </li> <li> <p>Researchers can start using immediately</p> </li> <li>No pipeline changes needed</li> <li> <p>Low risk</p> </li> <li> <p>Phase 2: Executor integration</p> </li> <li> <p>Connect helpers to pipeline permanences</p> </li> <li>Existing pipelines work unchanged</li> <li> <p>Medium risk</p> </li> <li> <p>Phase 3: Decorator support</p> </li> <li> <p>Enable function-to-process conversion</p> </li> <li>Add to builder registration</li> <li> <p>Medium risk</p> </li> <li> <p>Phase 4: Documentation &amp; examples</p> </li> <li>Create example scripts at each level</li> <li>Migration guides</li> <li>Low risk</li> </ol> <p>This allows incremental rollout with early value delivery.</p>"},{"location":"generated/path_management/","title":"Path Management and Deployment","text":"<p>This document explains how TensorImgPipeline manages paths and how the PathManager enables flexible project organization.</p>"},{"location":"generated/path_management/#overview","title":"Overview","text":"<p>TensorImgPipeline uses a centralized path management system that:</p> <ol> <li>Stores all pipelines in user-configurable directories</li> <li>Follows XDG Base Directory standards on Linux/Unix</li> <li>Supports environment variable overrides for testing and custom setups</li> </ol>"},{"location":"generated/path_management/#pathmanager","title":"PathManager","text":"<p>The <code>PathManager</code> class (in <code>tipi/paths.py</code>) provides appropriate paths for:</p> <ul> <li>Projects directory: Where pipeline packages are loaded from</li> <li>Configs directory: Where TOML configuration files are stored</li> <li>Cache directory: Where cloned git repositories are stored</li> </ul>"},{"location":"generated/path_management/#directory-structure","title":"Directory Structure","text":""},{"location":"generated/path_management/#default-paths","title":"Default Paths","text":"<pre><code># User's home directory\n~/.config/tipi/\n\u251c\u2500\u2500 projects/                   # \u2190 Projects loaded from here\n\u2502   \u251c\u2500\u2500 my_pipeline/           # User's custom pipeline\n\u2502   \u2514\u2500\u2500 cloned_pipeline/       # symlink to cache\n\u251c\u2500\u2500 configs/                    # \u2190 Configs loaded from here\n\u2502   \u251c\u2500\u2500 my_pipeline/\n\u2502   \u2502   \u2514\u2500\u2500 pipeline_config.toml\n\u2502   \u2514\u2500\u2500 cloned_pipeline/\n\u2502       \u2514\u2500\u2500 pipeline_config.toml\n\n~/.cache/tipi/  # \u2190 Git clones stored here\n\u2514\u2500\u2500 projects/\n    \u2514\u2500\u2500 cloned_pipeline/\n</code></pre>"},{"location":"generated/path_management/#xdg-base-directory-specification","title":"XDG Base Directory Specification","text":"<p>In production mode, PathManager follows the XDG Base Directory Specification:</p> <ul> <li><code>XDG_CONFIG_HOME</code> (default: <code>~/.config</code>): For configuration and project links</li> <li><code>XDG_CACHE_HOME</code> (default: <code>~/.cache</code>): For temporary data like git clones</li> </ul> <p>This ensures proper integration with Linux/Unix systems and respects user preferences.</p>"},{"location":"generated/path_management/#usage-examples","title":"Usage Examples","text":""},{"location":"generated/path_management/#check-your-current-configuration","title":"Check Your Current Configuration","text":"<pre><code>tipi info\n</code></pre> <p>This shows:</p> <ul> <li>All directory paths</li> <li>Directory existence status</li> </ul>"},{"location":"generated/path_management/#getting-started","title":"Getting Started","text":"<pre><code># 1. Install the package\npip install tensorimgpipeline\n\n# 2. Check configuration\ntipi info\n\n# 3. Create a new pipeline\ntipi create my_pipeline\n\n# 4. Link it\ntipi add ./my_pipeline\n# - Or use 'tipi add' to link external projects\n</code></pre>"},{"location":"generated/path_management/#production-workflow-end-users","title":"Production Workflow (End Users)","text":"<pre><code># 1. Install from PyPI\npip install tensorimgpipeline\n\n# Or use uvx for isolated execution\nuvx tensorimgpipeline --help\n\n# 2. Check mode (should show \"production\")\ntipi info\n\n# 3. Create or add custom pipelines\n# Option A: Create new pipeline\ntipi create my_pipeline\ncd my_pipeline\n# ... develop your pipeline ...\ncd ..\ntipi add ./my_pipeline\n\n# Option B: Clone from git\ntipi add https://github.com/user/awesome-pipeline.git\n\n# 4. Run your pipeline\ntipi run my_pipeline\n</code></pre>"},{"location":"generated/path_management/#hybrid-workflow-production-with-local-development","title":"Hybrid Workflow (Production with Local Development)","text":"<pre><code># 1. Install from PyPI for CLI tools\npip install tensorimgpipeline\n\n# 2. Develop pipelines separately\nmkdir ~/ml-pipelines\ncd ~/ml-pipelines\ntipi create image_segmentation\ncd image_segmentation\n# ... develop ...\n\n# 3. Link to production installation\ntipi add ~/ml-pipelines/image_segmentation\n\n# 4. Use like any other pipeline\ntipi list\ntipi run image_segmentation\n</code></pre>"},{"location":"generated/path_management/#environment-variables","title":"Environment Variables","text":"<p>For advanced use cases or testing, you can override the automatic detection:</p>"},{"location":"generated/path_management/#override-specific-directories","title":"Override Specific Directories","text":"<pre><code># Override projects directory\nexport TIPI_PROJECTS_DIR=/custom/path/projects\ntipi list\n\n# Override configs directory\nexport TIPI_CONFIG_DIR=/custom/path/configs\ntipi run my_pipeline\n\n# Override cache directory\nexport TIPI_CACHE_DIR=/custom/path/cache\ntipi add https://github.com/user/repo.git\n</code></pre> <p>Note: Environment variables are useful for testing and creating isolated environments.</p>"},{"location":"generated/path_management/#module-import-system","title":"Module Import System","text":"<p>The PathManager handles dynamic module imports by:</p> <ol> <li>Adding the projects directory to <code>sys.path</code></li> <li>Using standard Python import mechanisms</li> </ol> <pre><code># Dynamically adds projects directory to sys.path\n# Then imports my_pipeline\nmodule = path_manager.import_project_module(\"my_pipeline\")\n# Module is now available just like any installed package\n</code></pre> <p>This allows seamless imports regardless of where pipelines are located.</p>"},{"location":"generated/path_management/#best-practices","title":"Best Practices","text":""},{"location":"generated/path_management/#for-pipeline-developers","title":"For Pipeline Developers","text":"<ol> <li>Create standalone projects that can be added via <code>tipi add</code></li> </ol> <pre><code>tipi create my_pipeline\ncd my_pipeline\n# Edit your pipeline code\n</code></pre> <ol> <li>Link your project for testing</li> </ol> <pre><code>tipi add ./my_pipeline\ntipi validate my_pipeline\n</code></pre> <ol> <li>Use environment overrides for isolated testing</li> </ol> <pre><code>TIPI_PROJECTS_DIR=/tmp/test_projects tipi list\n</code></pre>"},{"location":"generated/path_management/#for-end-users","title":"For End Users","text":"<ol> <li>Installation: Use pip or uvx</li> </ol> <pre><code>pip install tensorimgpipeline\n# or\nuvx tensorimgpipeline\n</code></pre> <ol> <li> <p>Custom Pipelines: Store in <code>~/.config/tipi/projects/</code></p> </li> <li> <p>Create with <code>tipi create</code></p> </li> <li> <p>Or add existing with <code>tipi add</code></p> </li> <li> <p>Verification: Always check paths with <code>tipi info</code> when troubleshooting</p> </li> </ol>"},{"location":"generated/path_management/#for-system-administrators","title":"For System Administrators","text":"<ol> <li> <p>Multi-User Setup: Each user gets their own <code>~/.config/tipi/</code></p> </li> <li> <p>Shared Pipelines: Use git repositories</p> </li> </ol> <pre><code># Each user can clone\ntipi add https://company.com/shared-pipeline.git\n</code></pre> <ol> <li>Custom Paths: Set system-wide environment variables if needed    <pre><code># In /etc/environment or similar\nTIPI_PROJECTS_DIR=/opt/ml-pipelines/projects\nTIPI_CONFIG_DIR=/opt/ml-pipelines/configs\n</code></pre></li> </ol>"},{"location":"generated/path_management/#migration-guide","title":"Migration Guide","text":""},{"location":"generated/path_management/#packaging-your-pipeline-for-distribution","title":"Packaging Your Pipeline for Distribution","text":"<p>When you're ready to distribute your pipeline:</p> <ol> <li>Package your pipeline as a standalone project:</li> </ol> <pre><code>tipi create my_pipeline_standalone\n# Copy your code to the new project\n</code></pre> <ol> <li>Publish to git:</li> </ol> <pre><code>cd my_pipeline_standalone\ngit init\ngit add .\ngit commit -m \"Initial commit\"\ngit remote add origin &lt;url&gt;\ngit push\n</code></pre> <ol> <li>Users can now add it:    <pre><code>tipi add https://github.com/you/my_pipeline_standalone.git\n</code></pre></li> </ol>"},{"location":"generated/path_management/#from-standalone-to-integrated","title":"From Standalone to Integrated","text":"<p>If you have an existing Python package:</p> <ol> <li>Ensure proper structure:</li> </ol> <pre><code>my_package/\n\u251c\u2500\u2500 my_package/\n\u2502   \u251c\u2500\u2500 __init__.py        # Must have this\n\u2502   \u251c\u2500\u2500 permanences.py\n\u2502   \u2514\u2500\u2500 processes.py\n\u2514\u2500\u2500 configs/\n    \u2514\u2500\u2500 pipeline_config.toml\n</code></pre> <ol> <li>Add registration in <code>__init__.py</code>:</li> </ol> <pre><code>from my_package.permanences import MyPermanence\nfrom my_package.processes import MyProcess\n\npermanences_to_register = {\n    \"MyPermanence\": MyPermanence,\n}\n\nprocesses_to_register = {\n    \"MyProcess\": MyProcess,\n}\n</code></pre> <ol> <li>Link it:    <pre><code>tipi add ./my_package\n</code></pre></li> </ol>"},{"location":"generated/path_management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"generated/path_management/#pipeline-not-found","title":"Pipeline Not Found","text":"<pre><code># Check configuration\ntipi info\n\n# List available pipelines\ntipi list\n\n# Check ~/.config/tipi/projects/\n</code></pre>"},{"location":"generated/path_management/#config-not-found","title":"Config Not Found","text":"<pre><code># Check config directory\ntipi info\n\n# Inspect specific pipeline\ntipi inspect my_pipeline\n\n# Create config in ~/.config/tipi/configs/my_pipeline/\n</code></pre>"},{"location":"generated/path_management/#import-errors","title":"Import Errors","text":"<pre><code># Verify module structure\ntipi inspect my_pipeline\n\n# Check that __init__.py exists and has proper registration\nls -la ~/.config/tipi/projects/my_pipeline/\n\n# Validate the pipeline\ntipi validate my_pipeline\n</code></pre>"},{"location":"generated/path_management/#symlink-issues-linuxmac","title":"Symlink Issues (Linux/Mac)","text":"<pre><code># Check symlink\nls -la ~/.config/tipi/projects/\n\n# Recreate if broken\ntipi remove my_pipeline\ntipi add /path/to/my_pipeline\n</code></pre>"},{"location":"generated/path_management/#permission-issues","title":"Permission Issues","text":"<pre><code># Ensure proper ownership\nls -la ~/.config/tipi/\n\n# Fix if needed\nchmod -R u+rwX ~/.config/tipi/\n</code></pre>"},{"location":"generated/path_management/#api-reference","title":"API Reference","text":"<p>For advanced usage in Python code:</p> <pre><code>from tipi.paths import get_path_manager\n\n# Get the global PathManager instance\npm = get_path_manager()\n\n# Get directories\nprojects_dir = pm.get_projects_dir()\nconfigs_dir = pm.get_configs_dir()\ncache_dir = pm.get_cache_dir()\n\n# Get config path for specific pipeline\nconfig_path = pm.get_config_path(\"my_pipeline\", \"pipeline_config.toml\")\n\n# Import a project module\nmodule = pm.import_project_module(\"my_pipeline\")\n\n# Get configuration info\ninfo = pm.get_info()\nfor key, value in info.items():\n    print(f\"{key}: {value}\")\n\n# Setup Python path (automatically called by import_project_module)\npm.setup_python_path(\"my_pipeline\")\n</code></pre>"},{"location":"generated/path_management/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Complete CLI command documentation</li> <li>Installation Guide - Installation instructions</li> <li>Getting Started - First steps with pipelines</li> </ul>"},{"location":"generated/progressive_enhancement/","title":"Progressive Enhancement: From Script to Pipeline","text":"<p>This guide shows how to smoothly transition from experimental scripts to production-ready pipelines.</p>"},{"location":"generated/progressive_enhancement/#the-journey-5-levels-of-enhancement","title":"The Journey: 5 Levels of Enhancement","text":""},{"location":"generated/progressive_enhancement/#level-0-raw-script-start-here","title":"Level 0: Raw Script (Start Here!)","text":"<p>You're a researcher with an idea. Start with a normal Python script:</p> <pre><code># train.py\nimport torch\nfrom torch.utils.data import DataLoader\nfrom my_model import MyModel\n\n# Simple training script\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MyModel().to(device)\ndataset = MyDataset()\ndataloader = DataLoader(dataset, batch_size=32)\n\nprint(\"Starting training...\")\nfor epoch in range(10):\n    print(f\"Epoch {epoch+1}/10\")\n    for i, batch in enumerate(dataloader):\n        loss = train_step(model, batch, device)\n        if i % 10 == 0:\n            print(f\"Batch {i}, Loss: {loss:.4f}\")\n</code></pre> <p>Pros: Quick to write, easy to experiment Cons: No progress bars, no logging, hard to track experiments</p>"},{"location":"generated/progressive_enhancement/#level-1-add-progress-bars","title":"Level 1: Add Progress Bars","text":"<p>Want to see progress? Just add one import:</p> <pre><code># train.py\nimport torch\nfrom torch.utils.data import DataLoader\nfrom my_model import MyModel\nfrom tipi.helpers import progress_bar  # \u2190 Add this\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MyModel().to(device)\ndataset = MyDataset()\ndataloader = DataLoader(dataset, batch_size=32)\n\n# Add progress bars with minimal changes\nfor epoch in progress_bar(range(10), desc=\"Epochs\"):  # \u2190 Changed\n    for batch in progress_bar(dataloader, desc=\"Training\"):  # \u2190 Changed\n        loss = train_step(model, batch, device)\n</code></pre> <p>What you get:</p> <ul> <li>Beautiful progress bars (via Rich)</li> <li>Automatic time estimation</li> <li>Works exactly like <code>tqdm</code></li> <li>No pipeline required!</li> </ul> <p>Changes needed: 2 lines!</p>"},{"location":"generated/progressive_enhancement/#level-2-add-experiment-logging","title":"Level 2: Add Experiment Logging","text":"<p>Want to track your experiments in WandB?</p> <pre><code># train.py\nimport torch\nfrom torch.utils.data import DataLoader\nfrom my_model import MyModel\nfrom tipi.helpers import progress_bar, logger  # \u2190 Add logger\n\n# Initialize logging (runs once)\nlogger.init(project=\"my_research\", entity=\"my_team\")  # \u2190 Add this\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MyModel().to(device)\ndataset = MyDataset()\ndataloader = DataLoader(dataset, batch_size=32)\n\nfor epoch in progress_bar(range(10), desc=\"Epochs\"):\n    epoch_loss = 0\n    for batch in progress_bar(dataloader, desc=\"Training\"):\n        loss = train_step(model, batch, device)\n        epoch_loss += loss\n        logger.log({\"batch_loss\": loss})  # \u2190 Add this\n\n    logger.log({\"epoch_loss\": epoch_loss / len(dataloader)})  # \u2190 Add this\n</code></pre> <p>What you get:</p> <ul> <li>Automatic WandB logging</li> <li>Experiment tracking</li> <li>Metric visualization</li> <li>Still just a script!</li> </ul> <p>Changes needed: 3 lines!</p>"},{"location":"generated/progressive_enhancement/#level-3-better-device-management","title":"Level 3: Better Device Management","text":"<p>Tired of CUDA boilerplate?</p> <pre><code># train.py\nimport torch\nfrom torch.utils.data import DataLoader\nfrom my_model import MyModel\nfrom tipi.helpers import (\n    progress_bar,\n    logger,\n    device_manager  # \u2190 Add this\n)\n\nlogger.init(project=\"my_research\", entity=\"my_team\")\n\n# Let the helper pick the best device\ndevice = device_manager.get_device()  # \u2190 Simplified!\nmodel = MyModel().to(device)\ndataset = MyDataset()\ndataloader = DataLoader(dataset, batch_size=32)\n\nfor epoch in progress_bar(range(10), desc=\"Epochs\"):\n    for batch in progress_bar(dataloader, desc=\"Training\"):\n        loss = train_step(model, batch, device)\n        logger.log({\"loss\": loss})\n</code></pre> <p>What you get:</p> <ul> <li>Automatic best device selection</li> <li>Handles multi-GPU scenarios</li> <li>Checks VRAM availability</li> <li>Still just helpers!</li> </ul>"},{"location":"generated/progressive_enhancement/#level-4-extract-reusable-functions","title":"Level 4: Extract Reusable Functions","text":"<p>Your script is working great! Now extract functions for reuse:</p> <pre><code># train.py\nimport torch\nfrom torch.utils.data import DataLoader\nfrom my_model import MyModel\nfrom tipi.helpers import progress_bar, logger, device_manager\nfrom tipi.decorators import pipeline_process  # \u2190 New!\n\nlogger.init(project=\"my_research\", entity=\"my_team\")\n\ndef train_step(model, batch, device):\n    \"\"\"Your existing training logic\"\"\"\n    inputs, targets = batch\n    inputs, targets = inputs.to(device), targets.to(device)\n\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()\n\n@pipeline_process  # \u2190 Add decorator (optional for now)\ndef train_model(epochs: int = 10):\n    \"\"\"Now this function can become a pipeline process later!\"\"\"\n    device = device_manager.get_device()\n    model = MyModel().to(device)\n    dataset = MyDataset()\n    dataloader = DataLoader(dataset, batch_size=32)\n\n    for epoch in progress_bar(range(epochs), desc=\"Epochs\"):\n        for batch in progress_bar(dataloader, desc=\"Training\"):\n            loss = train_step(model, batch, device)\n            logger.log({\"loss\": loss})\n\n    return model\n\n# Still works as a script!\nif __name__ == \"__main__\":\n    trained_model = train_model(epochs=10)\n    torch.save(trained_model.state_dict(), \"model.pth\")\n</code></pre> <p>What you get:</p> <ul> <li>Reusable functions</li> <li>Ready for pipeline conversion</li> <li>Still runs as a script</li> <li>Type hints for parameters</li> </ul> <p>The decorator: <code>@pipeline_process</code> doesn't change behavior yet, but makes the function pipeline-ready!</p>"},{"location":"generated/progressive_enhancement/#level-5-convert-to-full-pipeline","title":"Level 5: Convert to Full Pipeline","text":"<p>Ready for production? Create a config file and you're done!</p>"},{"location":"generated/progressive_enhancement/#step-1-organize-your-code","title":"Step 1: Organize your code","text":"<pre><code># processes/training.py\nfrom tipi import PipelineProcess\nfrom tipi.helpers import progress_bar, logger\n\nclass TrainingProcess(PipelineProcess):\n    def __init__(self, controller, force: bool = False, epochs: int = 10):\n        super().__init__(controller, force)\n        self.epochs = epochs\n\n    def execute(self):\n        # Get permanences from pipeline\n        device = self.controller.get_permanence(\"device\")\n        model = self.controller.get_permanence(\"network\").model\n        dataloader = self.controller.get_permanence(\"data\").train_loader\n\n        # Your SAME training logic from Level 4!\n        for epoch in progress_bar(range(self.epochs), desc=\"Epochs\"):\n            for batch in progress_bar(dataloader, desc=\"Training\"):\n                loss = self.train_step(model, batch, device)\n                logger.log({\"loss\": loss})\n\n        return None\n\n    def train_step(self, model, batch, device):\n        \"\"\"Copy from your script - no changes!\"\"\"\n        # ... same code ...\n</code></pre>"},{"location":"generated/progressive_enhancement/#step-2-create-config","title":"Step 2: Create config","text":"<pre><code># configs/my_pipeline/execute_pipeline.toml\n\n[permanences.device]\ntype = \"Device\"\n\n[permanences.network]\ntype = \"Network\"\nparams = { model = \"resnet50\", num_classes = 10, pretrained = true }\n\n[permanences.data]\ntype = \"Data\"\nparams = { dataset = \"CIFAR10\", batch_size = 32 }\n\n[permanences.progress_manager]\ntype = \"ProgressManager\"\n\n[permanences.wandb_logger]\ntype = \"WandBManager\"\nparams = { project = \"my_research\", entity = \"my_team\" }\n\n[processes.training]\ntype = \"TrainingProcess\"\nparams = { epochs = 10 }\n\n[processes.validation]\ntype = \"ValidationProcess\"\n\n[processes.testing]\ntype = \"TestingProcess\"\n</code></pre>"},{"location":"generated/progressive_enhancement/#step-3-run-via-cli","title":"Step 3: Run via CLI","text":"<pre><code># Run the full pipeline\ntipi run my_pipeline\n\n# Or with different config\ntipi run my_pipeline --config custom_config.toml\n\n# Or programmatically\npython -c \"\nfrom tipi import PipelineRunner\nrunner = PipelineRunner('my_pipeline')\nrunner.run()\n\"\n</code></pre> <p>What you get:</p> <ul> <li>Full pipeline management</li> <li>Config-driven experiments</li> <li>Nested progress bars</li> <li>Permanence lifecycle management</li> <li>WandB sweep support</li> <li>Production-ready code</li> <li>Testable components</li> </ul>"},{"location":"generated/progressive_enhancement/#comparison-table","title":"Comparison Table","text":"Feature Level 0 Level 1 Level 2 Level 3 Level 4 Level 5 Lines of code 15 17 20 20 30 40+ Progress bars \u274c \u2705 \u2705 \u2705 \u2705 \u2705 Experiment logging \u274c \u274c \u2705 \u2705 \u2705 \u2705 Device management Manual Manual Manual \u2705 \u2705 \u2705 Reusable code \u274c \u274c \u274c \u274c \u2705 \u2705 Config-driven \u274c \u274c \u274c \u274c \u274c \u2705 Pipeline features \u274c \u274c \u274c \u274c \u274c \u2705 Testable \u274c \u274c \u274c \u274c \u26a0\ufe0f \u2705 Production-ready \u274c \u274c \u274c \u274c \u26a0\ufe0f \u2705"},{"location":"generated/progressive_enhancement/#key-principles","title":"Key Principles","text":""},{"location":"generated/progressive_enhancement/#1-zero-friction-start","title":"1. Zero Friction Start","text":"<ul> <li>Researchers start with normal scripts</li> <li>No framework knowledge required</li> <li>No config files needed initially</li> </ul>"},{"location":"generated/progressive_enhancement/#2-progressive-enhancement","title":"2. Progressive Enhancement","text":"<ul> <li>Each level adds ONE new concept</li> <li>Previous levels still work</li> <li>No forced migration</li> </ul>"},{"location":"generated/progressive_enhancement/#3-gradual-type-safety","title":"3. Gradual Type Safety","text":"<ul> <li>Start untyped (scripts)</li> <li>Add types when extracting functions (Level 4)</li> <li>Full type safety in pipeline (Level 5)</li> </ul>"},{"location":"generated/progressive_enhancement/#4-helpers-work-everywhere","title":"4. Helpers Work Everywhere","text":"<ul> <li><code>progress_bar()</code> works in scripts and pipelines</li> <li><code>logger</code> works standalone and with pipeline</li> <li><code>device_manager</code> adapts to context</li> </ul>"},{"location":"generated/progressive_enhancement/#5-copy-paste-friendly","title":"5. Copy-Paste Friendly","text":"<ul> <li>Training logic from Level 3 works in Level 5</li> <li>Functions can be copied between scripts and processes</li> <li>Minimal refactoring needed</li> </ul>"},{"location":"generated/progressive_enhancement/#example-real-research-workflow","title":"Example: Real Research Workflow","text":""},{"location":"generated/progressive_enhancement/#day-1-new-idea","title":"Day 1: New Idea","text":"<pre><code># quick_experiment.py\nfor epoch in range(5):\n    loss = train()\n    print(loss)\n</code></pre>"},{"location":"generated/progressive_enhancement/#day-2-looks-promising","title":"Day 2: Looks Promising","text":"<pre><code># quick_experiment.py\nfrom tipi.helpers import progress_bar, logger\n\nlogger.init(project=\"new_idea\")\n\nfor epoch in progress_bar(range(10)):\n    loss = train()\n    logger.log({\"loss\": loss})\n</code></pre>"},{"location":"generated/progressive_enhancement/#week-1-multiple-experiments","title":"Week 1: Multiple Experiments","text":"<pre><code># experiment_v1.py, experiment_v2.py, experiment_v3.py\n# All using helpers - easy to compare in WandB\n</code></pre>"},{"location":"generated/progressive_enhancement/#week-2-extract-common-code","title":"Week 2: Extract Common Code","text":"<pre><code># train_utils.py\n@pipeline_process\ndef train_model(learning_rate: float = 0.001):\n    # Shared training logic\n    pass\n\n# experiment_v4.py\nfrom train_utils import train_model\ntrain_model(learning_rate=0.01)\n</code></pre>"},{"location":"generated/progressive_enhancement/#month-1-production-pipeline","title":"Month 1: Production Pipeline","text":"<pre><code># configs/production/pipeline.toml\n[processes.training]\ntype = \"train_model\"  # Your function!\nparams = { learning_rate = 0.001 }\n</code></pre> <pre><code>tipi run production\n</code></pre>"},{"location":"generated/progressive_enhancement/#migration-checklist","title":"Migration Checklist","text":"<p>Moving from Level N to Level N+1:</p>"},{"location":"generated/progressive_enhancement/#level-0-1-add-progress-bars","title":"Level 0 \u2192 1: Add Progress Bars","text":"<ul> <li>[ ] Import <code>progress_bar</code> from helpers</li> <li>[ ] Wrap your loops with <code>progress_bar()</code></li> <li>[ ] Add descriptive names</li> </ul>"},{"location":"generated/progressive_enhancement/#level-1-2-add-logging","title":"Level 1 \u2192 2: Add Logging","text":"<ul> <li>[ ] Import <code>logger</code> from helpers</li> <li>[ ] Call <code>logger.init()</code> once at start</li> <li>[ ] Add <code>logger.log()</code> calls for metrics</li> </ul>"},{"location":"generated/progressive_enhancement/#level-2-3-better-device-management","title":"Level 2 \u2192 3: Better Device Management","text":"<ul> <li>[ ] Import <code>device_manager</code> from helpers</li> <li>[ ] Replace device selection with <code>device_manager.get_device()</code></li> </ul>"},{"location":"generated/progressive_enhancement/#level-3-4-extract-functions","title":"Level 3 \u2192 4: Extract Functions","text":"<ul> <li>[ ] Identify reusable code blocks</li> <li>[ ] Extract into functions with type hints</li> <li>[ ] Add <code>@pipeline_process</code> decorator</li> <li>[ ] Test standalone execution</li> </ul>"},{"location":"generated/progressive_enhancement/#level-4-5-full-pipeline","title":"Level 4 \u2192 5: Full Pipeline","text":"<ul> <li>[ ] Create <code>processes/</code> directory</li> <li>[ ] Convert functions to <code>PipelineProcess</code> classes</li> <li>[ ] Create TOML config file</li> <li>[ ] Register in pipeline builder</li> <li>[ ] Test via CLI</li> </ul>"},{"location":"generated/progressive_enhancement/#tips-for-researchers","title":"Tips for Researchers","text":""},{"location":"generated/progressive_enhancement/#when-to-move-to-the-next-level","title":"When to move to the next level?","text":"<p>Level 0 \u2192 1: When you're tired of seeing <code>print()</code> statements Level 1 \u2192 2: When you lose track of which experiment was which Level 2 \u2192 3: When GPU selection becomes annoying Level 3 \u2192 4: When you copy-paste code between experiments Level 4 \u2192 5: When you need to run in production or share with team</p>"},{"location":"generated/progressive_enhancement/#you-dont-have-to-reach-level-5","title":"You don't have to reach Level 5!","text":"<ul> <li>Many experiments stay at Level 2-3</li> <li>Only productionize what's proven to work</li> <li>Keep prototyping at lower levels</li> </ul>"},{"location":"generated/progressive_enhancement/#mix-and-match","title":"Mix and match","text":"<pre><code># experiment_hybrid.py\nfrom tipi.helpers import progress_bar, logger\nfrom my_pipeline.processes.training import train_epoch  # \u2190 From Level 5\n\n# Quick experiment using production code\nfor epoch in progress_bar(range(3)):\n    loss = train_epoch(my_model, data)  # \u2190 Production function\n    logger.log({\"quick_test\": loss})    # \u2190 Script logging\n</code></pre>"},{"location":"generated/progressive_enhancement/#questions","title":"Questions?","text":"<ul> <li> <p>Q: Do I have to use all helpers?   A: No! Use only what you need. <code>progress_bar</code> alone is useful.</p> </li> <li> <p>Q: Can I use this with my existing code?   A: Yes! Just import helpers and start adding them incrementally.</p> </li> <li> <p>Q: What if I don't want WandB?   A: <code>logger</code> will gracefully degrade to console output.</p> </li> <li> <p>Q: Can I stay at Level 3 forever?   A: Absolutely! Only move to Level 5 when you need production features.</p> </li> <li> <p>Q: Does this work with my existing tqdm code?   A: Yes! <code>progress_bar</code> is a drop-in replacement for <code>tqdm</code>.</p> </li> </ul>"},{"location":"modules/abstractions/","title":"abstractions.py","text":"<p>Abstract base classes for TensorImgPipeline.</p> <p>This package provides the core abstractions used throughout the pipeline framework.</p> <p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/abstractions/#tipi.abstractions.AbstractConfig","title":"<code>AbstractConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for configuration objects.</p> <p>Provides common functionality for: - Path string to Path object conversion - Parameter validation - Configuration validation</p> <p>Subclasses must implement the validate() method to define their specific validation logic.</p> Source code in <code>tipi/abstractions/config.py</code> <pre><code>@dataclass\nclass AbstractConfig(ABC):\n    \"\"\"Abstract base class for configuration objects.\n\n    Provides common functionality for:\n    - Path string to Path object conversion\n    - Parameter validation\n    - Configuration validation\n\n    Subclasses must implement the validate() method to define\n    their specific validation logic.\n    \"\"\"\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Post-initialization hook.\n\n        Applies path conversions and runs validation.\n        \"\"\"\n        self._apply_path()\n        self.validate()\n\n    @abstractmethod\n    def validate(self) -&gt; None:\n        \"\"\"Validate the configuration.\n\n        Subclasses should implement this method to check that all\n        configuration values are valid and meet requirements.\n\n        Raises:\n            InvalidConfigError: If configuration is invalid.\n        \"\"\"\n        ...\n\n    def validate_params(self, params: dict[str, Any], cls: type) -&gt; None:\n        \"\"\"Validate that parameters match a class constructor signature.\n\n        Args:\n            params: Dictionary of parameter names to values.\n            cls: The class whose constructor signature to validate against.\n\n        Raises:\n            InvalidConfigError: If params contain unexpected keys.\n        \"\"\"\n        signature = inspect.signature(cls)  # Get constructor signature\n\n        # Get expected parameters (excluding 'self')\n        expected_params = list(signature.parameters.keys())\n        if \"self\" in expected_params:\n            expected_params.remove(\"self\")\n\n        # Check if all required parameters are provided\n        if not set(params.keys()).issubset(expected_params):\n            raise InvalidConfigError(context=\"params-not-valid\", value=str(cls))\n\n    def _apply_path(self) -&gt; None:\n        \"\"\"Convert string fields to Path objects where appropriate.\n\n        Examines all dataclass fields and converts string values to Path\n        objects if the field's type hint includes Path in a Union.\n        \"\"\"\n        hints = get_type_hints(self.__class__)\n        for _field in fields(self):\n            field_name = _field.name\n            field_type = hints[field_name]\n            value = getattr(self, field_name)\n\n            # Check if the field type is a union\n            origin = get_origin(field_type)\n            if origin is Union:\n                args = get_args(field_type)\n                # If the field accepts Path and also a string type\n                if Path in args and isinstance(value, str):\n                    setattr(self, field_name, Path(value))\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.AbstractConfig.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Post-initialization hook.</p> <p>Applies path conversions and runs validation.</p> Source code in <code>tipi/abstractions/config.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Post-initialization hook.\n\n    Applies path conversions and runs validation.\n    \"\"\"\n    self._apply_path()\n    self.validate()\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.AbstractConfig.validate","title":"<code>validate()</code>  <code>abstractmethod</code>","text":"<p>Validate the configuration.</p> <p>Subclasses should implement this method to check that all configuration values are valid and meet requirements.</p> <p>Raises:</p> Type Description <code>InvalidConfigError</code> <p>If configuration is invalid.</p> Source code in <code>tipi/abstractions/config.py</code> <pre><code>@abstractmethod\ndef validate(self) -&gt; None:\n    \"\"\"Validate the configuration.\n\n    Subclasses should implement this method to check that all\n    configuration values are valid and meet requirements.\n\n    Raises:\n        InvalidConfigError: If configuration is invalid.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.AbstractConfig.validate_params","title":"<code>validate_params(params, cls)</code>","text":"<p>Validate that parameters match a class constructor signature.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict[str, Any]</code> <p>Dictionary of parameter names to values.</p> required <code>cls</code> <code>type</code> <p>The class whose constructor signature to validate against.</p> required <p>Raises:</p> Type Description <code>InvalidConfigError</code> <p>If params contain unexpected keys.</p> Source code in <code>tipi/abstractions/config.py</code> <pre><code>def validate_params(self, params: dict[str, Any], cls: type) -&gt; None:\n    \"\"\"Validate that parameters match a class constructor signature.\n\n    Args:\n        params: Dictionary of parameter names to values.\n        cls: The class whose constructor signature to validate against.\n\n    Raises:\n        InvalidConfigError: If params contain unexpected keys.\n    \"\"\"\n    signature = inspect.signature(cls)  # Get constructor signature\n\n    # Get expected parameters (excluding 'self')\n    expected_params = list(signature.parameters.keys())\n    if \"self\" in expected_params:\n        expected_params.remove(\"self\")\n\n    # Check if all required parameters are provided\n    if not set(params.keys()).issubset(expected_params):\n        raise InvalidConfigError(context=\"params-not-valid\", value=str(cls))\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.AbstractController","title":"<code>AbstractController</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for pipeline controllers.</p> <p>Controllers manage the execution flow of pipeline processes, including progress reporting and process lifecycle management.</p> Source code in <code>tipi/abstractions/controller.py</code> <pre><code>class AbstractController(ABC):\n    \"\"\"Abstract base class for pipeline controllers.\n\n    Controllers manage the execution flow of pipeline processes,\n    including progress reporting and process lifecycle management.\n    \"\"\"\n\n    @abstractmethod\n    def add_process(self, process: \"PipelineProcess\") -&gt; None:\n        \"\"\"Add a process to the controller's execution queue.\n\n        Args:\n            process: The pipeline process to add.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _get_progress_decorator(self) -&gt; Callable:\n        \"\"\"Get a decorator for progress reporting.\n\n        Returns:\n            A decorator function that wraps process execution with\n            progress reporting capabilities.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.AbstractController.add_process","title":"<code>add_process(process)</code>  <code>abstractmethod</code>","text":"<p>Add a process to the controller's execution queue.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>PipelineProcess</code> <p>The pipeline process to add.</p> required Source code in <code>tipi/abstractions/controller.py</code> <pre><code>@abstractmethod\ndef add_process(self, process: \"PipelineProcess\") -&gt; None:\n    \"\"\"Add a process to the controller's execution queue.\n\n    Args:\n        process: The pipeline process to add.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.Permanence","title":"<code>Permanence</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for objects that persist through the entire pipeline lifecycle.</p> <p>Permanences are stateful resources that: - Store structured data needed throughout pipeline execution - Are accessed by processes via controller.get_permanence(name) - Have managed lifecycles with hooks - Are extensible through abstraction</p> Example <pre><code>class MyDataPermanence(Permanence):\n    def __init__(self, path: Path):\n        self.data = self._load_data(path)\n\n    def initialize(self) -&gt; None:\n        # Setup phase - called before any process runs\n        self._validate_data()\n\n    def checkpoint(self) -&gt; None:\n        # Save intermediate state\n        self._save_checkpoint()\n\n    def cleanup(self) -&gt; None:\n        # Release resources\n        del self.data\n</code></pre> Source code in <code>tipi/abstractions/permanence.py</code> <pre><code>class Permanence(ABC):\n    \"\"\"Base class for objects that persist through the entire pipeline lifecycle.\n\n    Permanences are stateful resources that:\n    - Store structured data needed throughout pipeline execution\n    - Are accessed by processes via controller.get_permanence(name)\n    - Have managed lifecycles with hooks\n    - Are extensible through abstraction\n\n    Example:\n        ```python\n        class MyDataPermanence(Permanence):\n            def __init__(self, path: Path):\n                self.data = self._load_data(path)\n\n            def initialize(self) -&gt; None:\n                # Setup phase - called before any process runs\n                self._validate_data()\n\n            def checkpoint(self) -&gt; None:\n                # Save intermediate state\n                self._save_checkpoint()\n\n            def cleanup(self) -&gt; None:\n                # Release resources\n                del self.data\n        ```\n    \"\"\"\n\n    @abstractmethod\n    def cleanup(self) -&gt; None:\n        \"\"\"Cleans up data from RAM or VRAM.\n\n        Called after all processes complete or on error.\n        Should release any held resources (memory, file handles, connections).\n\n        Raises:\n            Exception: If cleanup fails\n        \"\"\"\n        ...\n\n    def initialize(self) -&gt; None:\n        \"\"\"Initialize the permanence before pipeline execution.\n\n        Called once after all permanences are constructed but before\n        any process runs. Use for validation, resource allocation, or\n        setup that depends on other permanences.\n\n        Raises:\n            Exception: If initialization fails\n        \"\"\"\n        return\n\n    def checkpoint(self) -&gt; None:\n        \"\"\"Save intermediate state during pipeline execution.\n\n        Called at configurable checkpoints during execution.\n        Use for saving progress, creating backups, or logging state.\n\n        Raises:\n            Exception: If checkpointing fails\n        \"\"\"\n        return\n\n    def validate(self) -&gt; None:\n        \"\"\"Validate the permanence state.\n\n        Called to verify permanence is in valid state.\n        Use for health checks, data validation, or consistency checks.\n\n        Raises:\n            Exception: If validation fails\n        \"\"\"\n        return\n\n    def get_state(self) -&gt; dict[str, Any]:\n        \"\"\"Get serializable state for inspection or debugging.\n\n        Returns a dictionary representation of the permanence state.\n        Useful for logging, debugging, or state inspection.\n\n        Returns:\n            dict[str, Any]: Dictionary containing permanence state.\n        \"\"\"\n        return {\n            \"type\": self.__class__.__name__,\n            \"initialized\": True,\n        }\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.Permanence.checkpoint","title":"<code>checkpoint()</code>","text":"<p>Save intermediate state during pipeline execution.</p> <p>Called at configurable checkpoints during execution. Use for saving progress, creating backups, or logging state.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If checkpointing fails</p> Source code in <code>tipi/abstractions/permanence.py</code> <pre><code>def checkpoint(self) -&gt; None:\n    \"\"\"Save intermediate state during pipeline execution.\n\n    Called at configurable checkpoints during execution.\n    Use for saving progress, creating backups, or logging state.\n\n    Raises:\n        Exception: If checkpointing fails\n    \"\"\"\n    return\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.Permanence.cleanup","title":"<code>cleanup()</code>  <code>abstractmethod</code>","text":"<p>Cleans up data from RAM or VRAM.</p> <p>Called after all processes complete or on error. Should release any held resources (memory, file handles, connections).</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If cleanup fails</p> Source code in <code>tipi/abstractions/permanence.py</code> <pre><code>@abstractmethod\ndef cleanup(self) -&gt; None:\n    \"\"\"Cleans up data from RAM or VRAM.\n\n    Called after all processes complete or on error.\n    Should release any held resources (memory, file handles, connections).\n\n    Raises:\n        Exception: If cleanup fails\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.Permanence.get_state","title":"<code>get_state()</code>","text":"<p>Get serializable state for inspection or debugging.</p> <p>Returns a dictionary representation of the permanence state. Useful for logging, debugging, or state inspection.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing permanence state.</p> Source code in <code>tipi/abstractions/permanence.py</code> <pre><code>def get_state(self) -&gt; dict[str, Any]:\n    \"\"\"Get serializable state for inspection or debugging.\n\n    Returns a dictionary representation of the permanence state.\n    Useful for logging, debugging, or state inspection.\n\n    Returns:\n        dict[str, Any]: Dictionary containing permanence state.\n    \"\"\"\n    return {\n        \"type\": self.__class__.__name__,\n        \"initialized\": True,\n    }\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.Permanence.initialize","title":"<code>initialize()</code>","text":"<p>Initialize the permanence before pipeline execution.</p> <p>Called once after all permanences are constructed but before any process runs. Use for validation, resource allocation, or setup that depends on other permanences.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If initialization fails</p> Source code in <code>tipi/abstractions/permanence.py</code> <pre><code>def initialize(self) -&gt; None:\n    \"\"\"Initialize the permanence before pipeline execution.\n\n    Called once after all permanences are constructed but before\n    any process runs. Use for validation, resource allocation, or\n    setup that depends on other permanences.\n\n    Raises:\n        Exception: If initialization fails\n    \"\"\"\n    return\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.Permanence.validate","title":"<code>validate()</code>","text":"<p>Validate the permanence state.</p> <p>Called to verify permanence is in valid state. Use for health checks, data validation, or consistency checks.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If validation fails</p> Source code in <code>tipi/abstractions/permanence.py</code> <pre><code>def validate(self) -&gt; None:\n    \"\"\"Validate the permanence state.\n\n    Called to verify permanence is in valid state.\n    Use for health checks, data validation, or consistency checks.\n\n    Raises:\n        Exception: If validation fails\n    \"\"\"\n    return\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.PipelineProcess","title":"<code>PipelineProcess</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for pipeline processes.</p> <p>A process represents a unit of work within the pipeline that: - Can access permanences via a controller/manager - Can be skipped based on conditions - Executes its main logic via execute() - Can be forced to run via the force parameter</p> Example <pre><code>class MyProcess(PipelineProcess):\n    def __init__(self, controller, force: bool):\n        super().__init__(controller, force)\n        self.data = controller.get_permanence(\"data\")\n\n    def skip(self) -&gt; bool:\n        return not self.force and self.data.is_cached()\n\n    def execute(self) -&gt; None:\n        # Process logic here\n        self.data.process()\n</code></pre> Source code in <code>tipi/abstractions/process.py</code> <pre><code>class PipelineProcess(ABC):\n    \"\"\"Abstract base class for pipeline processes.\n\n    A process represents a unit of work within the pipeline that:\n    - Can access permanences via a controller/manager\n    - Can be skipped based on conditions\n    - Executes its main logic via execute()\n    - Can be forced to run via the force parameter\n\n    Example:\n        ```python\n        class MyProcess(PipelineProcess):\n            def __init__(self, controller, force: bool):\n                super().__init__(controller, force)\n                self.data = controller.get_permanence(\"data\")\n\n            def skip(self) -&gt; bool:\n                return not self.force and self.data.is_cached()\n\n            def execute(self) -&gt; None:\n                # Process logic here\n                self.data.process()\n        ```\n    \"\"\"\n\n    def __init__(self, controller: Any, force: bool) -&gt; None:\n        \"\"\"Initialize the process.\n\n        When overriding this method, make sure to call super().__init__(controller, force).\n\n        Args:\n            controller: The controller/manager providing access to permanences.\n                       Should have a get_permanence(name: str) method.\n            force: If True, process should run even if outputs exist.\n        \"\"\"\n        self.controller = controller\n        self.force = force\n\n    @abstractmethod\n    def execute(self) -&gt; None:\n        \"\"\"Execute the process logic.\n\n        This method should contain the main work of the process.\n        It should handle any errors internally or let them propagate.\n\n        Raises:\n            Exception: Any exceptions during execution.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def skip(self) -&gt; bool:\n        \"\"\"Determine if the process should be skipped.\n\n        Returns:\n            True if the process should be skipped, False otherwise.\n            Common reasons to skip:\n            - Outputs already exist and force=False\n            - Required inputs are missing\n            - Conditional execution based on config\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.PipelineProcess.__init__","title":"<code>__init__(controller, force)</code>","text":"<p>Initialize the process.</p> <p>When overriding this method, make sure to call super().init(controller, force).</p> <p>Parameters:</p> Name Type Description Default <code>controller</code> <code>Any</code> <p>The controller/manager providing access to permanences.        Should have a get_permanence(name: str) method.</p> required <code>force</code> <code>bool</code> <p>If True, process should run even if outputs exist.</p> required Source code in <code>tipi/abstractions/process.py</code> <pre><code>def __init__(self, controller: Any, force: bool) -&gt; None:\n    \"\"\"Initialize the process.\n\n    When overriding this method, make sure to call super().__init__(controller, force).\n\n    Args:\n        controller: The controller/manager providing access to permanences.\n                   Should have a get_permanence(name: str) method.\n        force: If True, process should run even if outputs exist.\n    \"\"\"\n    self.controller = controller\n    self.force = force\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.PipelineProcess.execute","title":"<code>execute()</code>  <code>abstractmethod</code>","text":"<p>Execute the process logic.</p> <p>This method should contain the main work of the process. It should handle any errors internally or let them propagate.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Any exceptions during execution.</p> Source code in <code>tipi/abstractions/process.py</code> <pre><code>@abstractmethod\ndef execute(self) -&gt; None:\n    \"\"\"Execute the process logic.\n\n    This method should contain the main work of the process.\n    It should handle any errors internally or let them propagate.\n\n    Raises:\n        Exception: Any exceptions during execution.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.PipelineProcess.skip","title":"<code>skip()</code>  <code>abstractmethod</code>","text":"<p>Determine if the process should be skipped.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the process should be skipped, False otherwise.</p> <code>bool</code> <p>Common reasons to skip:</p> <code>bool</code> <ul> <li>Outputs already exist and force=False</li> </ul> <code>bool</code> <ul> <li>Required inputs are missing</li> </ul> <code>bool</code> <ul> <li>Conditional execution based on config</li> </ul> Source code in <code>tipi/abstractions/process.py</code> <pre><code>@abstractmethod\ndef skip(self) -&gt; bool:\n    \"\"\"Determine if the process should be skipped.\n\n    Returns:\n        True if the process should be skipped, False otherwise.\n        Common reasons to skip:\n        - Outputs already exist and force=False\n        - Required inputs are missing\n        - Conditional execution based on config\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.ProcessConfig","title":"<code>ProcessConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractConfig</code></p> <p>Base configuration for pipeline processes.</p> <p>Attributes:</p> Name Type Description <code>force</code> <code>bool</code> <p>If True, forces execution even if outputs exist.</p> Source code in <code>tipi/abstractions/config.py</code> <pre><code>@dataclass\nclass ProcessConfig(AbstractConfig):\n    \"\"\"Base configuration for pipeline processes.\n\n    Attributes:\n        force: If True, forces execution even if outputs exist.\n    \"\"\"\n\n    force: bool = False\n\n    def validate(self) -&gt; None:\n        \"\"\"Validate the process configuration.\n\n        Raises:\n            InvalidConfigError: If force is not a boolean.\n        \"\"\"\n        if not isinstance(self.force, bool):\n            raise InvalidConfigError(context=\"invalid-force-type\", value=f\"{self.force=}\")\n</code></pre>"},{"location":"modules/abstractions/#tipi.abstractions.ProcessConfig.validate","title":"<code>validate()</code>","text":"<p>Validate the process configuration.</p> <p>Raises:</p> Type Description <code>InvalidConfigError</code> <p>If force is not a boolean.</p> Source code in <code>tipi/abstractions/config.py</code> <pre><code>def validate(self) -&gt; None:\n    \"\"\"Validate the process configuration.\n\n    Raises:\n        InvalidConfigError: If force is not a boolean.\n    \"\"\"\n    if not isinstance(self.force, bool):\n        raise InvalidConfigError(context=\"invalid-force-type\", value=f\"{self.force=}\")\n</code></pre>"},{"location":"modules/builder/","title":"builder.py","text":"<p>This module provides the implementation of the PipelineBuilder class, which is responsible for building and configuring a pipeline of processes and permanences for the TensorImgPipeline project.</p> <p>The PipelineBuilder class allows for the registration of classes, loading of configuration files, validation of configuration sections, and construction of the complete pipeline. It handles errors related to configuration loading, class instantiation, and process addition.</p> <p>Classes:</p> Name Description <code>PipelineBuilder</code> <p>A class to build and configure a pipeline of processes and permanences.</p> <p>Functions:</p> Name Description <code>get_objects_for_pipeline</code> <p>str) -&gt; dict[str, type]: Retrieves and combines objects to be registered for a given pipeline.</p> <p>Usage Example:</p>"},{"location":"modules/builder/#tipi.core.builder--todo-add-usage-example","title":"TODO: Add usage example","text":"<p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/builder/#tipi.core.builder.PipelineBuilder","title":"<code>PipelineBuilder</code>","text":"<p>Builds pipeline components from configuration.</p> Source code in <code>tipi/core/builder.py</code> <pre><code>class PipelineBuilder:\n    \"\"\"Builds pipeline components from configuration.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the builder with empty registries.\"\"\"\n        self._registry: dict[str, type[Permanence] | type[PipelineProcess]] = {}\n        self._config: dict[str, Any] = {}\n        self._config_path: Path | None = None\n\n    def build(self) -&gt; tuple[dict[str, Permanence], list[ProcessWithParams]]:\n        \"\"\"Construct permanences and process specifications.\n\n        Returns:\n            Tuple of (permanences_dict, process_specs_list)\n\n        Raises:\n            ConfigSectionError: If config sections are invalid\n            InstTypeError: If permanence/process instantiation fails\n            RegistryError: If class not found in registry\n        \"\"\"\n        # First, create core permanences from pipeline flags\n        permanences = self._build_core_permanences()\n\n        # Then add user-defined permanences (can override core)\n        user_permanences = self._build_permanences()\n        permanences.update(user_permanences)\n\n        # Build processes\n        processes = self._build_processes()\n        return permanences, processes\n\n    def register_class(self, name: str, class_type: type) -&gt; None:\n        \"\"\"Register a permanence or process class.\n\n        Args:\n            name: Name to register the class under\n            class_type: The class to register\n\n        Raises:\n            RegistryError: If registration fails or class is invalid\n        \"\"\"\n        if not isinstance(class_type, type):\n            raise RegistryError(f\"Cannot register {name}: {class_type} is not a class\")\n\n        # Validate that it's a Permanence or PipelineProcess\n        if not (issubclass(class_type, Permanence) or issubclass(class_type, PipelineProcess)):\n            raise RegistryError(\n                f\"Cannot register {name}: {class_type.__name__} must be a subclass of Permanence or PipelineProcess\"\n            )\n\n        self._registry[name] = class_type\n\n    def load_config(self, path: Path) -&gt; None:\n        \"\"\"Load configuration from file.\n\n        Args:\n            path: Path to the TOML configuration file\n\n        Raises:\n            ConfigNotFoundError: If config file doesn't exist\n            ConfigInvalidTomlError: If TOML parsing fails\n            ConfigPermissionError: If file can't be read\n        \"\"\"\n        self._config_path = path\n\n        # Check if file exists\n        if not path.exists():\n            raise ConfigNotFoundError(f\"Configuration file not found: {path}\")\n\n        # Check if we can read it\n        if not os.access(path, os.R_OK):\n            raise ConfigPermissionError(f\"Cannot read configuration file: {path}\")\n\n        # Load and parse TOML\n        try:\n            with open(path, \"rb\") as f:\n                self._config = toml_load(f)\n        except TOMLDecodeError as e:\n            raise ConfigInvalidTomlError(f\"Invalid TOML in {path}: {e}\") from e\n        except Exception as e:\n            raise ConfigPermissionError(f\"Error reading {path}: {e}\") from e\n\n        # Validate config structure\n        if \"permanences\" not in self._config and \"processes\" not in self._config and \"pipeline\" not in self._config:\n            raise ConfigSectionError(\n                f\"Configuration file {path} must contain at least one of \"\n                f\"'pipeline', 'permanences' or 'processes' sections\"\n            )\n\n    def _build_core_permanences(self) -&gt; dict[str, Permanence]:\n        \"\"\"Build core framework permanences from pipeline flags.\n\n        Core permanences can be enabled via simple flags in [pipeline] section:\n        - enable_progress: Creates a ProgressManager\n        - enable_wandb: Creates a WandBLogger\n\n        Returns:\n            Dictionary mapping core permanence names to instances\n\n        Raises:\n            InstTypeError: If core permanence instantiation fails\n            ConfigSectionError: If pipeline section is invalid\n        \"\"\"\n        core_permanences: dict[str, Permanence] = {}\n\n        # Get pipeline configuration section\n        pipeline_config = self._config.get(\"pipeline\", {})\n        if not isinstance(pipeline_config, dict):\n            raise ConfigSectionError(\"'pipeline' section must be a table\")\n\n        # Check if user explicitly defined these in permanences section\n        user_permanences = self._config.get(\"permanences\", {})\n\n        # Build ProgressManager if enabled and not explicitly overridden\n        if (\n            pipeline_config.get(\"enable_progress\", False)\n            and \"progress_manager\" not in user_permanences\n            and \"ProgressManager\" in self._registry\n        ):\n            try:\n                # Create ProgressManager with direct=True to initialize .live\n                perm_class = cast(type[Permanence], self._registry[\"ProgressManager\"])\n                progress_manager = perm_class(direct=True)  # type: ignore[call-arg]\n                core_permanences[\"progress_manager\"] = progress_manager\n            except Exception as e:\n                raise InstTypeError(f\"Failed to create ProgressManager: {e}\") from e\n\n        # Build WandBLogger if enabled and not explicitly overridden\n        if (\n            pipeline_config.get(\"enable_wandb\", False)\n            and \"wandb_logger\" not in user_permanences\n            and \"WandBManager\" in self._registry\n        ):\n            try:\n                # WandBManager might need config parameters\n                wandb_config = pipeline_config.get(\"wandb\", {})\n                perm_class = cast(type[Permanence], self._registry[\"WandBManager\"])\n                wandb_logger = perm_class(**wandb_config)\n                core_permanences[\"wandb_logger\"] = wandb_logger\n            except Exception as e:\n                raise InstTypeError(f\"Failed to create WandBManager: {e}\") from e\n\n        return core_permanences\n\n    def _build_permanences(self) -&gt; dict[str, Permanence]:\n        \"\"\"Build permanence instances from config.\n\n        Returns:\n            Dictionary mapping permanence names to instances\n\n        Raises:\n            InstTypeError: If permanence instantiation fails\n            ConfigSectionError: If permanences section is invalid\n        \"\"\"\n        permanences: dict[str, Permanence] = {}\n\n        permanences_config = self._config.get(\"permanences\", {})\n        if not isinstance(permanences_config, dict):\n            raise ConfigSectionError(\"'permanences' section must be a dict\")\n\n        for name, perm_config in permanences_config.items():\n            if not isinstance(perm_config, dict):\n                raise ConfigSectionError(f\"Permanence '{name}' configuration must be a dict\")\n\n            if \"type\" not in perm_config:\n                raise ConfigSectionError(f\"Permanence '{name}' missing required 'type' field\")\n\n            perm_type_name = perm_config[\"type\"]\n\n            # Look up the class in registry\n            if perm_type_name not in self._registry:\n                raise RegistryError(\n                    f\"Permanence type '{perm_type_name}' for '{name}' not registered. \"\n                    f\"Available types: {list(self._registry.keys())}\"\n                )\n\n            perm_class = self._registry[perm_type_name]\n\n            # Verify it's actually a Permanence\n            if not issubclass(perm_class, Permanence):\n                raise InstTypeError(f\"Registered class '{perm_type_name}' is not a Permanence subclass\")\n\n            # Extract constructor parameters (everything except 'type')\n            perm_params = {k: v for k, v in perm_config.items() if k != \"type\"}\n\n            # Instantiate the permanence\n            try:\n                permanence = perm_class(**perm_params)\n                permanences[name] = permanence\n            except TypeError as e:\n                raise InstTypeError(f\"Failed to instantiate permanence '{name}' of type '{perm_type_name}': {e}\") from e\n            except Exception as e:\n                raise InstTypeError(f\"Error creating permanence '{name}' of type '{perm_type_name}': {e}\") from e\n\n        return permanences\n\n    def _build_processes(self) -&gt; list[ProcessWithParams]:\n        \"\"\"Build process specifications from config.\n\n        Returns:\n            List of ProcessWithParams specifications\n\n        Raises:\n            InstTypeError: If process instantiation fails\n            ConfigSectionError: If processes section is invalid\n        \"\"\"\n        process_specs: list[ProcessWithParams] = []\n\n        processes_config = self._config.get(\"processes\", {})\n        if not isinstance(processes_config, dict):\n            raise ConfigSectionError(\"'processes' section must be a table\")\n\n        for name, proc_config in processes_config.items():\n            if not isinstance(proc_config, dict):\n                raise ConfigSectionError(f\"Process '{name}' configuration must be a table\")\n\n            if \"type\" not in proc_config:\n                raise ConfigSectionError(f\"Process '{name}' missing required 'type' field\")\n\n            proc_type_name = proc_config[\"type\"]\n\n            # Look up the class in registry\n            if proc_type_name not in self._registry:\n                raise RegistryError(\n                    f\"Process type '{proc_type_name}' for '{name}' not registered. \"\n                    f\"Available types: {list(self._registry.keys())}\"\n                )\n\n            proc_class = self._registry[proc_type_name]\n\n            # Verify it's actually a PipelineProcess\n            if not issubclass(proc_class, PipelineProcess):\n                raise InstTypeError(f\"Registered class '{proc_type_name}' is not a PipelineProcess subclass\")\n\n            # Extract parameters (everything except 'type')\n            proc_params = {k: v for k, v in proc_config.items() if k != \"type\"}\n\n            # Create ProcessWithParams spec (not instantiated yet)\n            process_spec = ProcessWithParams(process=proc_class, params=proc_params)\n            process_specs.append(process_spec)\n\n        return process_specs\n</code></pre>"},{"location":"modules/builder/#tipi.core.builder.PipelineBuilder.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the builder with empty registries.</p> Source code in <code>tipi/core/builder.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the builder with empty registries.\"\"\"\n    self._registry: dict[str, type[Permanence] | type[PipelineProcess]] = {}\n    self._config: dict[str, Any] = {}\n    self._config_path: Path | None = None\n</code></pre>"},{"location":"modules/builder/#tipi.core.builder.PipelineBuilder.build","title":"<code>build()</code>","text":"<p>Construct permanences and process specifications.</p> <p>Returns:</p> Type Description <code>tuple[dict[str, Permanence], list[ProcessWithParams]]</code> <p>Tuple of (permanences_dict, process_specs_list)</p> <p>Raises:</p> Type Description <code>ConfigSectionError</code> <p>If config sections are invalid</p> <code>InstTypeError</code> <p>If permanence/process instantiation fails</p> <code>RegistryError</code> <p>If class not found in registry</p> Source code in <code>tipi/core/builder.py</code> <pre><code>def build(self) -&gt; tuple[dict[str, Permanence], list[ProcessWithParams]]:\n    \"\"\"Construct permanences and process specifications.\n\n    Returns:\n        Tuple of (permanences_dict, process_specs_list)\n\n    Raises:\n        ConfigSectionError: If config sections are invalid\n        InstTypeError: If permanence/process instantiation fails\n        RegistryError: If class not found in registry\n    \"\"\"\n    # First, create core permanences from pipeline flags\n    permanences = self._build_core_permanences()\n\n    # Then add user-defined permanences (can override core)\n    user_permanences = self._build_permanences()\n    permanences.update(user_permanences)\n\n    # Build processes\n    processes = self._build_processes()\n    return permanences, processes\n</code></pre>"},{"location":"modules/builder/#tipi.core.builder.PipelineBuilder.load_config","title":"<code>load_config(path)</code>","text":"<p>Load configuration from file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the TOML configuration file</p> required <p>Raises:</p> Type Description <code>ConfigNotFoundError</code> <p>If config file doesn't exist</p> <code>ConfigInvalidTomlError</code> <p>If TOML parsing fails</p> <code>ConfigPermissionError</code> <p>If file can't be read</p> Source code in <code>tipi/core/builder.py</code> <pre><code>def load_config(self, path: Path) -&gt; None:\n    \"\"\"Load configuration from file.\n\n    Args:\n        path: Path to the TOML configuration file\n\n    Raises:\n        ConfigNotFoundError: If config file doesn't exist\n        ConfigInvalidTomlError: If TOML parsing fails\n        ConfigPermissionError: If file can't be read\n    \"\"\"\n    self._config_path = path\n\n    # Check if file exists\n    if not path.exists():\n        raise ConfigNotFoundError(f\"Configuration file not found: {path}\")\n\n    # Check if we can read it\n    if not os.access(path, os.R_OK):\n        raise ConfigPermissionError(f\"Cannot read configuration file: {path}\")\n\n    # Load and parse TOML\n    try:\n        with open(path, \"rb\") as f:\n            self._config = toml_load(f)\n    except TOMLDecodeError as e:\n        raise ConfigInvalidTomlError(f\"Invalid TOML in {path}: {e}\") from e\n    except Exception as e:\n        raise ConfigPermissionError(f\"Error reading {path}: {e}\") from e\n\n    # Validate config structure\n    if \"permanences\" not in self._config and \"processes\" not in self._config and \"pipeline\" not in self._config:\n        raise ConfigSectionError(\n            f\"Configuration file {path} must contain at least one of \"\n            f\"'pipeline', 'permanences' or 'processes' sections\"\n        )\n</code></pre>"},{"location":"modules/builder/#tipi.core.builder.PipelineBuilder.register_class","title":"<code>register_class(name, class_type)</code>","text":"<p>Register a permanence or process class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to register the class under</p> required <code>class_type</code> <code>type</code> <p>The class to register</p> required <p>Raises:</p> Type Description <code>RegistryError</code> <p>If registration fails or class is invalid</p> Source code in <code>tipi/core/builder.py</code> <pre><code>def register_class(self, name: str, class_type: type) -&gt; None:\n    \"\"\"Register a permanence or process class.\n\n    Args:\n        name: Name to register the class under\n        class_type: The class to register\n\n    Raises:\n        RegistryError: If registration fails or class is invalid\n    \"\"\"\n    if not isinstance(class_type, type):\n        raise RegistryError(f\"Cannot register {name}: {class_type} is not a class\")\n\n    # Validate that it's a Permanence or PipelineProcess\n    if not (issubclass(class_type, Permanence) or issubclass(class_type, PipelineProcess)):\n        raise RegistryError(\n            f\"Cannot register {name}: {class_type.__name__} must be a subclass of Permanence or PipelineProcess\"\n        )\n\n    self._registry[name] = class_type\n</code></pre>"},{"location":"modules/builder/#tipi.core.builder.get_objects_for_pipeline","title":"<code>get_objects_for_pipeline(pipeline_name)</code>","text":"<p>Retrieves and combines objects to be registered for a given pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline_name</code> <code>str</code> <p>The name of the pipeline for which to retrieve objects.</p> required <p>Returns:</p> Type Description <code>dict[str, type[Permanence] | type[PipelineProcess]]</code> <p>dict[str, type]: A dictionary containing the combined objects from              <code>permanences_to_register</code> and <code>processes_to_register</code>              of the specified pipeline module, with both instance names              and class names as keys.</p> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If the pipeline module cannot be found.</p> Source code in <code>tipi/core/builder.py</code> <pre><code>def get_objects_for_pipeline(\n    pipeline_name: str,\n) -&gt; dict[str, type[Permanence] | type[PipelineProcess]]:\n    \"\"\"\n    Retrieves and combines objects to be registered for a given pipeline.\n\n    Args:\n        pipeline_name (str): The name of the pipeline for which to retrieve objects.\n\n    Returns:\n        dict[str, type]: A dictionary containing the combined objects from\n                         `permanences_to_register` and `processes_to_register`\n                         of the specified pipeline module, with both instance names\n                         and class names as keys.\n\n    Raises:\n        ModuleNotFoundError: If the pipeline module cannot be found.\n    \"\"\"\n    # Try built-in pipelines first\n    full_module_name = \"tipi.pipelines.\" + pipeline_name\n    if pipeline_name == \"core\":\n        full_module_name = \"tipi.\" + pipeline_name\n\n    module = None\n\n    # Attempt 1: Try built-in pipelines\n    with contextlib.suppress(ModuleNotFoundError):\n        module = importlib.import_module(full_module_name)\n\n    # Attempt 2: Try loading from user projects directory (symlinked projects)\n    if module is None:\n        path_manager = get_path_manager()\n        module = path_manager.import_project_module(pipeline_name)\n\n    # If all attempts failed, raise an error\n    if module is None:\n        raise ModuleNotFoundError(\n            f\"Pipeline '{pipeline_name}' not found. \"\n            f\"Tried built-in module '{full_module_name}' and user projects directory.\"\n        )\n\n    # Get the registries\n    if not hasattr(module, \"permanences_to_register\") or not hasattr(module, \"processes_to_register\"):\n        raise AttributeError(\n            f\"Module '{pipeline_name}' must define 'permanences_to_register' and 'processes_to_register' dictionaries\"\n        )\n\n    # Combine the registries and also register by class name\n    combined: dict[str, type[Permanence] | type[PipelineProcess]] = {}\n\n    # Add permanences with both instance names and class names\n    for cls in module.permanences_to_register:\n        combined[cls.__name__] = cls  # Class name (e.g., 'ConfigPermanence')\n\n    # Add processes with both instance names and class names\n    for cls in module.processes_to_register:\n        combined[cls.__name__] = cls  # Class name (e.g., 'LoadDataProcess')\n\n    return combined\n</code></pre>"},{"location":"modules/controller/","title":"controller.py","text":"<p>This module defines an PipelineController responsible for managing a pipeline of processes and handling potential errors that occur during their execution.</p> <p>Classes:</p> Name Description <code>PipelineController</code> <p>Manages a pipeline of processes and handles errors that occur during.</p> <p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/controller/#tipi.core.controller.PipelineController","title":"<code>PipelineController</code>","text":"<p>Coordinates pipeline permanences and processes.</p> <p>Responsibilities: - Manage permanence lifecycle - Provide permanence access to processes - Instantiate processes with their parameters - Yield processes for execution</p> Source code in <code>tipi/core/controller.py</code> <pre><code>class PipelineController:\n    \"\"\"Coordinates pipeline permanences and processes.\n\n    Responsibilities:\n    - Manage permanence lifecycle\n    - Provide permanence access to processes\n    - Instantiate processes with their parameters\n    - Yield processes for execution\n    \"\"\"\n\n    def __init__(self, permanences: dict[str, Permanence], process_specs: list[ProcessWithParams]) -&gt; None:\n        self._permanences = permanences\n        self._process_specs = process_specs\n\n    def get_permanence(self, name: str, default: Any = _MISSING) -&gt; Any:\n        \"\"\"Get a permanence by name.\n\n        Args:\n            name: Name of the permanence to retrieve\n            default: Value to return if permanence not found. If not provided,\n                    raises PermanenceKeyError instead. Can be None.\n\n        Returns:\n            The permanence instance or default value\n\n        Raises:\n            PermanenceKeyError: If permanence not found and no default provided\n        \"\"\"\n        if default is not _MISSING:\n            return self._permanences.get(name, default)\n        if name not in self._permanences:\n            raise PermanenceKeyError(ErrorCode.PERMA_KEY, key=name)\n        return self._permanences[name]\n\n    def iterate_processes(self) -&gt; Iterator[tuple[int, PipelineProcess]]:\n        \"\"\"Yield (index, process_instance) for execution.\"\"\"\n        for idx, spec in enumerate(self._process_specs):\n            process_instance = spec.get_instance(self)\n            yield idx, process_instance\n\n    def get_process_count(self) -&gt; int:\n        \"\"\"Get total number of processes.\"\"\"\n        return len(self._process_specs)\n\n    def iterate_permanences(self) -&gt; Iterator[Permanence]:\n        \"\"\"Yield permanence instances for cleanup or inspection.\"\"\"\n        yield from self._permanences.values()\n\n    def get_permanence_count(self) -&gt; int:\n        \"\"\"Get total number of permanences.\"\"\"\n        return len(self._permanences)\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Cleanup all permanences.\"\"\"\n        for permanence in self._permanences.values():\n            permanence.cleanup()\n</code></pre>"},{"location":"modules/controller/#tipi.core.controller.PipelineController.cleanup","title":"<code>cleanup()</code>","text":"<p>Cleanup all permanences.</p> Source code in <code>tipi/core/controller.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Cleanup all permanences.\"\"\"\n    for permanence in self._permanences.values():\n        permanence.cleanup()\n</code></pre>"},{"location":"modules/controller/#tipi.core.controller.PipelineController.get_permanence","title":"<code>get_permanence(name, default=_MISSING)</code>","text":"<p>Get a permanence by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the permanence to retrieve</p> required <code>default</code> <code>Any</code> <p>Value to return if permanence not found. If not provided,     raises PermanenceKeyError instead. Can be None.</p> <code>_MISSING</code> <p>Returns:</p> Type Description <code>Any</code> <p>The permanence instance or default value</p> <p>Raises:</p> Type Description <code>PermanenceKeyError</code> <p>If permanence not found and no default provided</p> Source code in <code>tipi/core/controller.py</code> <pre><code>def get_permanence(self, name: str, default: Any = _MISSING) -&gt; Any:\n    \"\"\"Get a permanence by name.\n\n    Args:\n        name: Name of the permanence to retrieve\n        default: Value to return if permanence not found. If not provided,\n                raises PermanenceKeyError instead. Can be None.\n\n    Returns:\n        The permanence instance or default value\n\n    Raises:\n        PermanenceKeyError: If permanence not found and no default provided\n    \"\"\"\n    if default is not _MISSING:\n        return self._permanences.get(name, default)\n    if name not in self._permanences:\n        raise PermanenceKeyError(ErrorCode.PERMA_KEY, key=name)\n    return self._permanences[name]\n</code></pre>"},{"location":"modules/controller/#tipi.core.controller.PipelineController.get_permanence_count","title":"<code>get_permanence_count()</code>","text":"<p>Get total number of permanences.</p> Source code in <code>tipi/core/controller.py</code> <pre><code>def get_permanence_count(self) -&gt; int:\n    \"\"\"Get total number of permanences.\"\"\"\n    return len(self._permanences)\n</code></pre>"},{"location":"modules/controller/#tipi.core.controller.PipelineController.get_process_count","title":"<code>get_process_count()</code>","text":"<p>Get total number of processes.</p> Source code in <code>tipi/core/controller.py</code> <pre><code>def get_process_count(self) -&gt; int:\n    \"\"\"Get total number of processes.\"\"\"\n    return len(self._process_specs)\n</code></pre>"},{"location":"modules/controller/#tipi.core.controller.PipelineController.iterate_permanences","title":"<code>iterate_permanences()</code>","text":"<p>Yield permanence instances for cleanup or inspection.</p> Source code in <code>tipi/core/controller.py</code> <pre><code>def iterate_permanences(self) -&gt; Iterator[Permanence]:\n    \"\"\"Yield permanence instances for cleanup or inspection.\"\"\"\n    yield from self._permanences.values()\n</code></pre>"},{"location":"modules/controller/#tipi.core.controller.PipelineController.iterate_processes","title":"<code>iterate_processes()</code>","text":"<p>Yield (index, process_instance) for execution.</p> Source code in <code>tipi/core/controller.py</code> <pre><code>def iterate_processes(self) -&gt; Iterator[tuple[int, PipelineProcess]]:\n    \"\"\"Yield (index, process_instance) for execution.\"\"\"\n    for idx, spec in enumerate(self._process_specs):\n        process_instance = spec.get_instance(self)\n        yield idx, process_instance\n</code></pre>"},{"location":"modules/errors/","title":"errors.py","text":"<p>Error handling for tensor image pipeline.</p> <p>This module implements error handling for configuration, registry and execution of the pipeline.</p> <p>Copyright (C) 2025 Matti Kaupenjohann</p> <p>This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"modules/errors/#tipi.errors.BuilderError","title":"<code>BuilderError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>RuntimeError</code></p> Source code in <code>tipi/errors.py</code> <pre><code>@dataclass\nclass BuilderError(RuntimeError):\n    error_value: Any\n    error_code: ErrorCode | None = None\n\n    def __post_init__(self) -&gt; None:\n        pass\n\n    def _set_error_code(self, error_code: ErrorCode) -&gt; None:\n        \"\"\"Set the error code (called by subclasses).\"\"\"\n        self.error_code = error_code\n\n    def __str__(self) -&gt; str:\n        if self.error_code:\n            return f\"[{self.error_code.code}]: {self.error_code.message}: {self.error_value}\"\n        return f\"BuilderError: {self.error_value}\"\n</code></pre>"},{"location":"modules/errors/#tipi.errors.ConfigInvalidTomlError","title":"<code>ConfigInvalidTomlError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when the configuration file is not valid toml</p> Source code in <code>tipi/errors.py</code> <pre><code>class ConfigInvalidTomlError(BuilderError):\n    \"\"\"Raised when the configuration file is not valid toml\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        self._set_error_code(ErrorCode.CONFIG_INVALID)\n</code></pre>"},{"location":"modules/errors/#tipi.errors.ConfigNotFoundError","title":"<code>ConfigNotFoundError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when the builder configuration file does not exists</p> Source code in <code>tipi/errors.py</code> <pre><code>class ConfigNotFoundError(BuilderError):\n    \"\"\"Raised when the builder configuration file does not exists\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        self._set_error_code(ErrorCode.CONFIG_MISSING)\n</code></pre>"},{"location":"modules/errors/#tipi.errors.ConfigPermissionError","title":"<code>ConfigPermissionError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when the builder configuration file does not exists</p> Source code in <code>tipi/errors.py</code> <pre><code>class ConfigPermissionError(BuilderError):\n    \"\"\"Raised when the builder configuration file does not exists\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        self._set_error_code(ErrorCode.CONFIG_PERMISSION)\n</code></pre>"},{"location":"modules/errors/#tipi.errors.ConfigSectionError","title":"<code>ConfigSectionError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised for config section missing</p> Source code in <code>tipi/errors.py</code> <pre><code>class ConfigSectionError(BuilderError):\n    \"\"\"Raised for config section missing\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        self._set_error_code(ErrorCode.CONFIG_SECTION)\n</code></pre>"},{"location":"modules/errors/#tipi.errors.ExecutionError","title":"<code>ExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised during process execution failures</p> Source code in <code>tipi/errors.py</code> <pre><code>class ExecutionError(Exception):\n    \"\"\"Raised during process execution failures\"\"\"\n\n    def __init__(self, process: str, error: Exception):\n        error_code = ErrorCode.PROCESS_EXECUTION\n        super().__init__(f\"[{error_code.code}]: Process {process} failed with {error}\")\n</code></pre>"},{"location":"modules/errors/#tipi.errors.InstTypeError","title":"<code>InstTypeError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised when type in config not set</p> Source code in <code>tipi/errors.py</code> <pre><code>class InstTypeError(BuilderError):\n    \"\"\"Raised when type in config not set\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        self._set_error_code(ErrorCode.INST_TYPE)\n</code></pre>"},{"location":"modules/errors/#tipi.errors.RegistryError","title":"<code>RegistryError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised for class registration issues</p> Source code in <code>tipi/errors.py</code> <pre><code>class RegistryError(BuilderError):\n    \"\"\"Raised for class registration issues\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        self._set_error_code(ErrorCode.REGISTRY_INVALID)\n</code></pre>"},{"location":"modules/errors/#tipi.errors.RegistryParamError","title":"<code>RegistryParamError</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BuilderError</code></p> <p>Raised for class instatioation with wrong params</p> Source code in <code>tipi/errors.py</code> <pre><code>class RegistryParamError(BuilderError):\n    \"\"\"Raised for class instatioation with wrong params\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        self._set_error_code(ErrorCode.REGISTRY_PARAM)\n</code></pre>"}]}